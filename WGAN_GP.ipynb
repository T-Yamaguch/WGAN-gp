{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN_GP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Yamaguch/WGAN-gp/blob/master/WGAN_GP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Tzp4G4_cKs",
        "outputId": "668ee9dd-44ec-405f-f826-25c9f0c9cfc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCaY7uIeBtcK",
        "outputId": "fd57cc9d-0630-403b-c6aa-4ce18631a094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Oct  1 23:11:23 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JkBM0L4_c9H"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Concatenate, Conv2D, \\\n",
        "MaxPooling2D, Activation, ReLU, LeakyReLU, UpSampling2D, BatchNormalization, \\\n",
        "Dropout, Dense, Flatten, Add, LayerNormalization, GaussianNoise, Reshape, Lambda\n",
        "from keras.regularizers import l2\n",
        "\n",
        "class up_block(Model):\n",
        "  def __init__(self, filter_num, kernel_size, kernel_regularizer= l2(0.001)):\n",
        "    super(up_block, self).__init__()\n",
        "    self.conv = Conv2D(filter_num, kernel_size, padding = 'same', kernel_regularizer= kernel_regularizer)\n",
        "    self.norm = BatchNormalization(trainable=True)\n",
        "    self.act = LeakyReLU()\n",
        "    self.up = UpSampling2D((2,2))\n",
        "    self.noise = GaussianNoise(0.2)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.norm(x)\n",
        "    x = self.act(x)\n",
        "    x = self.up(x)\n",
        "    x = self.noise(x)\n",
        "    return x\n",
        "\n",
        "class res_block(Model):\n",
        "  def __init__(self, filter_num, kernel_size, kernel_regularizer= l2(0.001)):\n",
        "    super(res_block, self).__init__()\n",
        "    self.conv1 = Conv2D(filter_num, kernel_size, padding = 'same', kernel_regularizer= kernel_regularizer)\n",
        "    self.conv2 = Conv2D(filter_num, kernel_size, padding = 'same', kernel_regularizer= kernel_regularizer)\n",
        "    self.norm1 = BatchNormalization(trainable=True)\n",
        "    self.norm2 = BatchNormalization(trainable=True)\n",
        "    self.act1 = LeakyReLU()\n",
        "    self.act2 = LeakyReLU()\n",
        "    self.add = Add()\n",
        "\n",
        "  def call(self, x):\n",
        "    y = self.conv1(x)\n",
        "    y = self.norm1(y)\n",
        "    y = self.act1(y)\n",
        "    y = self.conv2(y)\n",
        "    y = self.norm2(y)\n",
        "    y = self.act2(y)\n",
        "    x = self.add([x, y])\n",
        "    return x\n",
        "\n",
        "class down_block(Model):\n",
        "  def __init__(self, filter_num, kernel_size, kernel_regularizer= l2(0.001)):\n",
        "    super(down_block, self).__init__()\n",
        "    self.conv = Conv2D(filter_num, kernel_size, padding = 'same', kernel_regularizer= kernel_regularizer)\n",
        "    self.norm = BatchNormalization(trainable=True)\n",
        "    self.act = LeakyReLU()\n",
        "    self.pooling = MaxPooling2D((2,2), strides=(2,2))\n",
        "    self.drop = Dropout(0.3)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.norm(x)\n",
        "    x = self.act(x)\n",
        "    x = self.pooling(x)\n",
        "    x = self.drop(x)\n",
        "    return x\n",
        "\n",
        "class conv_block(Model):\n",
        "  def __init__(self, filter_num, kernel_size, kernel_regularizer= l2(0.001), batch_norm = True):\n",
        "    super(conv_block, self).__init__()\n",
        "    self.conv = Conv2D(filter_num, kernel_size, padding = 'same', kernel_regularizer= kernel_regularizer)\n",
        "    self.norm = BatchNormalization(trainable=True)\n",
        "    self.act = LeakyReLU()\n",
        "    self.drop = Dropout(0.3)\n",
        "    self.batch_norm = batch_norm\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv(x)\n",
        "    if self.batch_norm == True:\n",
        "      x = self.norm(x)\n",
        "    x = self.act(x)\n",
        "    x = self.drop(x)\n",
        "    return x\n",
        "\n",
        "class dense_block(Model):\n",
        "  def __init__(self, filter_num, kernel_regularizer= l2(0.001), batch_norm = True):\n",
        "    super(dense_block, self).__init__()\n",
        "    self.dense = Dense(filter_num, kernel_regularizer= kernel_regularizer)\n",
        "    self.norm = BatchNormalization(trainable=True)\n",
        "    self.act = LeakyReLU()\n",
        "    self.batch_norm = batch_norm\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.dense(x)\n",
        "    if self.batch_norm == True:\n",
        "      x = self.norm(x)\n",
        "    x = self.act(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx2s6XE9_mkK",
        "outputId": "83163e40-0bef-4246-edfe-f77d87bb929c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "class Generator():\n",
        "  def __init__(self):\n",
        "    self.channel_num = 2048\n",
        "    self.layer_num = 5\n",
        "    self.res_num = 0\n",
        "    self.latent_num = 8\n",
        "    self.inputs = Input(shape=(self.latent_num)) \n",
        "    self.kernel_size = (5, 5)\n",
        "    self.name = 'generator'\n",
        "    self.kernel_regularizer= None\n",
        "      \n",
        "  def model(self):\n",
        "    x = self.inputs\n",
        "\n",
        "    final_size = 4*4*self.channel_num\n",
        "    data_size = self.latent_num\n",
        "\n",
        "    # while data_size*64 < final_size:\n",
        "    #   data_size *= 64\n",
        "    #   x = dense_block(data_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "\n",
        "    x = dense_block(final_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "    x = Reshape((4, 4, self.channel_num))(x)\n",
        "\n",
        "    filter_num = self.channel_num\n",
        "    \n",
        "    for n in range(self.layer_num):\n",
        "      for m in range(self.res_num):\n",
        "        x = res_block(filter_num, self.kernel_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "      # x = conv_block(filter_num, self.kernel_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "      filter_num /= 2\n",
        "      x = up_block(filter_num, self.kernel_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "\n",
        "    for m in range(self.res_num):\n",
        "      x = res_block(filter_num, self.kernel_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "    # x = conv_block(filter_num, self.kernel_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "\n",
        "    x = Conv2D(3, self.kernel_size, padding = 'same', kernel_regularizer= self.kernel_regularizer)(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    outputs = x\n",
        "    return Model(inputs = self.inputs, outputs = outputs, name = self.name)\n",
        "\n",
        "g = Generator()\n",
        "g.model().summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 8)]               0         \n",
            "_________________________________________________________________\n",
            "dense_block (dense_block)    (None, 32768)             425984    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 4, 4, 2048)        0         \n",
            "_________________________________________________________________\n",
            "up_block (up_block)          (None, 8, 8, 1024)        52433920  \n",
            "_________________________________________________________________\n",
            "up_block_1 (up_block)        (None, 16, 16, 512)       13109760  \n",
            "_________________________________________________________________\n",
            "up_block_2 (up_block)        (None, 32, 32, 256)       3278080   \n",
            "_________________________________________________________________\n",
            "up_block_3 (up_block)        (None, 64, 64, 128)       819840    \n",
            "_________________________________________________________________\n",
            "up_block_4 (up_block)        (None, 128, 128, 64)      205120    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 128, 128, 3)       4803      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 128, 128, 3)       0         \n",
            "=================================================================\n",
            "Total params: 70,277,507\n",
            "Trainable params: 70,208,003\n",
            "Non-trainable params: 69,504\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ie8PcTw_nEC",
        "outputId": "f479752e-5efd-4f70-eab6-41d114582082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "class Discriminator():\n",
        "  def __init__(self):\n",
        "    self.channel_num = 32\n",
        "    self.layer_num = 5\n",
        "    self.input_shape = (128, 128, 3)\n",
        "    self.inputs = Input(shape=self.input_shape)\n",
        "    self.kernel_size = (5, 5)\n",
        "    self.name = 'discriminator'\n",
        "    self.kernel_regularizer= None\n",
        "\n",
        "  def model(self):\n",
        "    x = self.inputs\n",
        "\n",
        "    filter_num = self.channel_num\n",
        "    for n in range(self.layer_num):\n",
        "      # x = conv_block(filter_num, self.kernel_size, kernel_regularizer= self.kernel_regularizer, batch_norm = False)(x)\n",
        "      x = down_block(filter_num, self.kernel_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "      filter_num *= 2\n",
        "\n",
        "    x = conv_block(filter_num, self.kernel_size, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "    x = Flatten()(x)\n",
        "    outputs =  Dense(1, kernel_regularizer= self.kernel_regularizer)(x)\n",
        "\n",
        "    return Model(inputs = self.inputs, outputs = outputs, name = self.name)\n",
        "\n",
        "d = Discriminator()\n",
        "d.model().summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "down_block (down_block)      (None, 64, 64, 32)        2560      \n",
            "_________________________________________________________________\n",
            "down_block_1 (down_block)    (None, 32, 32, 64)        51520     \n",
            "_________________________________________________________________\n",
            "down_block_2 (down_block)    (None, 16, 16, 128)       205440    \n",
            "_________________________________________________________________\n",
            "down_block_3 (down_block)    (None, 8, 8, 256)         820480    \n",
            "_________________________________________________________________\n",
            "down_block_4 (down_block)    (None, 4, 4, 512)         3279360   \n",
            "_________________________________________________________________\n",
            "conv_block (conv_block)      (None, 4, 4, 1024)        13112320  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 16385     \n",
            "=================================================================\n",
            "Total params: 17,488,065\n",
            "Trainable params: 17,484,033\n",
            "Non-trainable params: 4,032\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyTiix-n_pgj",
        "outputId": "16b82f63-27ff-4b4f-b719-db13cdaae971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.losses import binary_crossentropy, MSE\n",
        "import glob\n",
        "import time\n",
        "import random\n",
        "import sys\n",
        "\n",
        "class WGAN():\n",
        "  def __init__(self, \n",
        "               img_size= 128, \n",
        "               code_num = 2048,\n",
        "               batch_size = 16, \n",
        "               train_epochs = 100, \n",
        "               train_steps = 8, \n",
        "               checkpoint_epochs = 25, \n",
        "               image_epochs = 1, \n",
        "               start_epoch = 1,\n",
        "               optimizer = Adam(learning_rate = 1e-4),\n",
        "               n_critics = 8,\n",
        "               gp_lamda = 0.1\n",
        "               ):\n",
        "    \n",
        "    self.batch_size = batch_size\n",
        "    self.train_epochs =  train_epochs\n",
        "    self.train_steps = train_steps\n",
        "    self.checkpoint_epochs = checkpoint_epochs\n",
        "    self.image_epochs = image_epochs\n",
        "    self.start_epoch = start_epoch\n",
        "    self.code_num = code_num\n",
        "    self.img_size = img_size\n",
        "    self.n_critics = n_critics\n",
        "    self.gp_lamda = gp_lamda\n",
        "    \n",
        "    self.gen_optimizer = optimizer\n",
        "    self.disc_optimizer = optimizer\n",
        "\n",
        "    g = Generator()\n",
        "    self.gen = g.model()\n",
        "    \n",
        "    d = Discriminator()\n",
        "    self.disc = d.model()\n",
        "\n",
        "    checkpoint_dir = \"drive/My Drive/WGAN-gp/checkpoint\"\n",
        "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "    checkpoint = tf.train.Checkpoint(gen_optimizer = self.gen_optimizer,\n",
        "                                     disc_optimizer = self.disc_optimizer,\n",
        "                                     gen = self.gen,\n",
        "                                     disc = self.disc,\n",
        "                                     )\n",
        "\n",
        "    self.manager = tf.train.CheckpointManager(checkpoint, directory=checkpoint_dir, max_to_keep=2)\n",
        "\n",
        "    train_image_path = 'drive/My Drive/samples/image'\n",
        "    \n",
        "    self.train_filenames = glob.glob(train_image_path + '/*.jpg') \n",
        "\n",
        "    checkpoint.restore(self.manager.latest_checkpoint)\n",
        "\n",
        "    self.g_history = []\n",
        "    self.d_history = []\n",
        "    # self.endec_history = []  \n",
        "\n",
        "  def preprocess_image(self, image):\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [self.img_size, self.img_size] )\n",
        "    image = image/255  # normalize to [0,1] range\n",
        "    return tf.cast(image, tf.float32)\n",
        "\n",
        "  def load_and_preprocess_image(self, path):\n",
        "    image = tf.io.read_file(path)\n",
        "    return self.preprocess_image(image)\n",
        "\n",
        "  def dataset(self, paths, batch_size):\n",
        "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(paths)\n",
        "    img_ds = path_ds.map(self.load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "    img_ds = img_ds.batch(batch_size)\n",
        "    return img_ds\n",
        "\n",
        "  def image_preparation(self, filenames, batch_size, steps):\n",
        "    img_batch = []\n",
        "    while 1:\n",
        "      random.shuffle(filenames)\n",
        "      for path in filenames:\n",
        "        img_batch.append(path)\n",
        "        if len(img_batch) == steps*batch_size:\n",
        "          imgs = self.dataset(img_batch, batch_size)\n",
        "          img_batch = []\n",
        "          yield imgs\n",
        "\n",
        "  def discriminator_loss(self, original_outputs, generated_outputs):\n",
        "    real_loss = binary_crossentropy(tf.ones_like(original_outputs), original_outputs)\n",
        "    generated_loss = binary_crossentropy(tf.zeros_like(generated_outputs), generated_outputs)\n",
        "    loss_d = tf.math.reduce_mean(real_loss + generated_loss)\n",
        "    return loss_d\n",
        "\n",
        "  def generator_loss(self, generated_outputs):\n",
        "    loss_g = tf.math.reduce_mean(binary_crossentropy(tf.ones_like(generated_outputs), generated_outputs))\n",
        "    return loss_g\n",
        "\n",
        "  def mse_loss(self, true, pred):\n",
        "    loss =  tf.math.reduce_mean(MSE(true, pred))\n",
        "    return loss\n",
        "\n",
        "  def wasserstein_loss(self, ori_outputs, gen_outputs):\n",
        "    d_loss = -tf.reduce_mean(ori_outputs) + tf.reduce_mean(gen_outputs)\n",
        "    g_loss = -tf.reduce_mean(gen_outputs)\n",
        "    return d_loss, g_loss\n",
        "\n",
        "  def w_gp_loss(self, ori_outputs, gen_outputs, imgs, gen_imgs):\n",
        "    d_loss = -tf.reduce_mean(ori_outputs) + tf.reduce_mean(gen_outputs)\n",
        "    g_loss = -tf.reduce_mean(gen_outputs)\n",
        "\n",
        "    alpha = tf.random.uniform(shape=[self.batch_size, 1, 1, 1], minval=0, maxval=1, dtype=tf.dtypes.float32)\n",
        "    inter_sample = alpha * imgs + (1-alpha) * gen_imgs\n",
        "    with tf.GradientTape() as tape_gp:\n",
        "      tape_gp.watch(inter_sample)\n",
        "      inter_score = self.disc(inter_sample)\n",
        "    gp_gradients = tape_gp.gradient(inter_score, inter_sample)\n",
        "    gp_gradients_norm = tf.sqrt(tf.reduce_sum(tf.square(gp_gradients), axis = [1, 2, 3]))\n",
        "    gp = tf.reduce_mean((gp_gradients_norm - 1.0) ** 2)\n",
        "\n",
        "    d_loss += gp * self.gp_lamda\n",
        "    \n",
        "    return d_loss, g_loss\n",
        "\n",
        "\n",
        "  def g_train(self, imgs):\n",
        "    noise =tf.random.uniform([self.batch_size, self.code_num], minval=0, maxval=1, dtype=tf.dtypes.float32)\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      gen_imgs = self.gen(noise, training=True)\n",
        "\n",
        "      ori_outputs = self.disc(imgs, training=False)\n",
        "      gen_outputs = self.disc(gen_imgs, training=False)\n",
        "\n",
        "      _, g_loss = self.w_gp_loss(ori_outputs, gen_outputs, imgs, gen_imgs)\n",
        "      self.g_temp.append(g_loss)\n",
        "\n",
        "    gradients_of_gen = gen_tape.gradient(g_loss, self.gen.trainable_variables)\n",
        "    self.gen_optimizer.apply_gradients(zip(gradients_of_gen, self.gen.trainable_variables))\n",
        "\n",
        "  def d_train(self, imgs):\n",
        "    noise =tf.random.uniform([self.batch_size, self.code_num], minval=0, maxval=1, dtype=tf.dtypes.float32)\n",
        "\n",
        "    with tf.GradientTape() as disc_tape:\n",
        "      gen_imgs = self.gen(noise, training=False)\n",
        "\n",
        "      ori_outputs = self.disc(imgs, training=True)\n",
        "      gen_outputs = self.disc(gen_imgs, training=True)\n",
        "      \n",
        "      d_loss, _ = self.w_gp_loss(ori_outputs, gen_outputs, imgs, gen_imgs)\n",
        "      self.d_temp.append(d_loss)\n",
        "\n",
        "    gradients_of_disc = disc_tape.gradient(d_loss, self.disc.trainable_variables)    \n",
        "    self.disc_optimizer.apply_gradients(zip(gradients_of_disc, self.disc.trainable_variables))\n",
        "\n",
        "  def visualise_batch(self, s_1, epoch):\n",
        "    gen_img = self.gen(s_1)  \n",
        "    gen_img = (np.array(gen_img*255, np.uint8))\n",
        "    fig, axes = plt.subplots(4, 6)\n",
        "    for idx, img in enumerate(gen_img):\n",
        "      p, q = idx//6, idx%6\n",
        "      axes[p, q].imshow(img)\n",
        "      axes[p, q].axis('off')\n",
        "    \n",
        "    save_name = 'drive/My Drive/WGAN-gp/generated_image/'+'image_at_epoch_{:04d}.png'\n",
        "    plt.savefig(save_name.format(epoch), dpi=200)\n",
        "    # plt.pause(0.1)\n",
        "    plt.close('all')\n",
        "\n",
        "  def loss_vis(self):\n",
        "    plt.plot(self.g_history, 'b', self.d_history, 'r')\n",
        "    plt.title('blue: g  red: d')\n",
        "    plt.savefig('drive/My Drive/WGAN-gp/loss/gan_loss.png')\n",
        "    plt.close('all')\n",
        "\n",
        "  def update_loss_history(self):\n",
        "    d_batch_loss = sum(self.d_temp)/len(self.d_temp)\n",
        "    g_batch_loss = sum(self.g_temp)/len(self.g_temp)\n",
        "    print ('\\nd loss: {:.4f}, g loss: {:.4f}'.format(d_batch_loss, g_batch_loss))\n",
        "    self.d_history.append(d_batch_loss)\n",
        "    self.g_history.append(g_batch_loss)\n",
        "    self.d_temp = []\n",
        "    self.g_temp = []\n",
        "\n",
        "  def __call__(self):\n",
        "    sample_noise =tf.random.uniform([24, self.code_num], minval=0, maxval=1, dtype=tf.dtypes.float32)\n",
        "    image_loader = self.image_preparation(self.train_filenames, self.batch_size, self.train_steps)\n",
        "    self.d_temp = []\n",
        "    self.g_temp = []\n",
        "\n",
        "    for epoch in range(self.start_epoch, self.train_epochs+1):\n",
        "      \n",
        "      start_time = time.time()\n",
        "\n",
        "      print ('\\nepochs {}'.format(epoch))\n",
        "      imgs_ds = next(image_loader)\n",
        "\n",
        "      for steps, imgs in enumerate(imgs_ds):\n",
        "        print(\"\\r\" + 'steps{}'.format(steps+1), end=\"\")\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        self.d_train(imgs)\n",
        "\n",
        "        if steps % self.n_critics == 0:\n",
        "          self.g_train(imgs)\n",
        "        \n",
        "      self.update_loss_history()\n",
        "\n",
        "      epoch_time = time.time() - start_time\n",
        "      print (\"epoch time: {:.4f} [sec]\".format(epoch_time))\n",
        "                               \n",
        "      if epoch % self.image_epochs == 0:\n",
        "        self.visualise_batch(sample_noise, epoch)\n",
        "        self.loss_vis()\n",
        "\n",
        "      if epoch % self.checkpoint_epochs == 0:\n",
        "        print ('\\nSaving checkpoint at epoch{}\\n\\n'.format(epoch))\n",
        "        self.manager.save()\n",
        "      \n",
        "if __name__ == '__main__':\n",
        "  a = WGAN(img_size = 128,\n",
        "           code_num = 8,\n",
        "           batch_size = 64,\n",
        "           train_epochs = 10000, \n",
        "           train_steps = 32, \n",
        "           checkpoint_epochs = 100, \n",
        "           image_epochs = 1, \n",
        "           start_epoch = 471,\n",
        "           optimizer = Adam(learning_rate = 1e-7),\n",
        "           n_critics = 1,\n",
        "           gp_lamda = 10\n",
        "           )\n",
        "  a()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epochs 1\n",
            "steps32\n",
            "d loss: 9.2789, g loss: 0.0990\n",
            "epoch time: 33.5211 [sec]\n",
            "\n",
            "epochs 2\n",
            "steps32\n",
            "d loss: 7.5525, g loss: 0.2532\n",
            "epoch time: 29.5812 [sec]\n",
            "\n",
            "epochs 3\n",
            "steps32\n",
            "d loss: 5.3417, g loss: 0.3245\n",
            "epoch time: 29.5649 [sec]\n",
            "\n",
            "epochs 4\n",
            "steps32\n",
            "d loss: 2.8541, g loss: 0.2977\n",
            "epoch time: 29.5435 [sec]\n",
            "\n",
            "epochs 5\n",
            "steps32\n",
            "d loss: 0.2757, g loss: 0.1507\n",
            "epoch time: 29.5248 [sec]\n",
            "\n",
            "epochs 6\n",
            "steps32\n",
            "d loss: -1.8168, g loss: -0.1466\n",
            "epoch time: 29.5408 [sec]\n",
            "\n",
            "epochs 7\n",
            "steps32\n",
            "d loss: -2.9799, g loss: -0.5876\n",
            "epoch time: 29.5230 [sec]\n",
            "\n",
            "epochs 8\n",
            "steps32\n",
            "d loss: -2.3452, g loss: -1.1334\n",
            "epoch time: 29.5480 [sec]\n",
            "\n",
            "epochs 9\n",
            "steps32\n",
            "d loss: 0.3453, g loss: -1.7270\n",
            "epoch time: 29.5186 [sec]\n",
            "\n",
            "epochs 10\n",
            "steps32\n",
            "d loss: 4.4153, g loss: -2.2648\n",
            "epoch time: 29.5593 [sec]\n",
            "\n",
            "Saving checkpoint at epoch10\n",
            "\n",
            "\n",
            "\n",
            "epochs 11\n",
            "steps32\n",
            "d loss: 8.5883, g loss: -2.6811\n",
            "epoch time: 29.5820 [sec]\n",
            "\n",
            "epochs 12\n",
            "steps32\n",
            "d loss: 11.4780, g loss: -2.9024\n",
            "epoch time: 29.5381 [sec]\n",
            "\n",
            "epochs 13\n",
            "steps32\n",
            "d loss: 12.6589, g loss: -2.9598\n",
            "epoch time: 29.5235 [sec]\n",
            "\n",
            "epochs 14\n",
            "steps32\n",
            "d loss: 12.2365, g loss: -2.8659\n",
            "epoch time: 29.5779 [sec]\n",
            "\n",
            "epochs 15\n",
            "steps32\n",
            "d loss: 10.5731, g loss: -2.6767\n",
            "epoch time: 29.5300 [sec]\n",
            "\n",
            "epochs 16\n",
            "steps32\n",
            "d loss: 8.7281, g loss: -2.4445\n",
            "epoch time: 29.5355 [sec]\n",
            "\n",
            "epochs 17\n",
            "steps32\n",
            "d loss: 6.7427, g loss: -2.1979\n",
            "epoch time: 29.5332 [sec]\n",
            "\n",
            "epochs 18\n",
            "steps32\n",
            "d loss: 5.1813, g loss: -1.9705\n",
            "epoch time: 29.5124 [sec]\n",
            "\n",
            "epochs 19\n",
            "steps32\n",
            "d loss: 3.8235, g loss: -1.7565\n",
            "epoch time: 29.5203 [sec]\n",
            "\n",
            "epochs 20\n",
            "steps32\n",
            "d loss: 2.8546, g loss: -1.5673\n",
            "epoch time: 29.5304 [sec]\n",
            "\n",
            "Saving checkpoint at epoch20\n",
            "\n",
            "\n",
            "\n",
            "epochs 21\n",
            "steps32\n",
            "d loss: 2.1133, g loss: -1.4172\n",
            "epoch time: 29.5814 [sec]\n",
            "\n",
            "epochs 22\n",
            "steps32\n",
            "d loss: 1.5695, g loss: -1.2846\n",
            "epoch time: 29.5343 [sec]\n",
            "\n",
            "epochs 23\n",
            "steps32\n",
            "d loss: 1.2215, g loss: -1.1852\n",
            "epoch time: 29.5456 [sec]\n",
            "\n",
            "epochs 24\n",
            "steps32\n",
            "d loss: 0.9042, g loss: -1.0970\n",
            "epoch time: 29.5190 [sec]\n",
            "\n",
            "epochs 25\n",
            "steps32\n",
            "d loss: 0.7076, g loss: -1.0207\n",
            "epoch time: 29.5278 [sec]\n",
            "\n",
            "epochs 26\n",
            "steps32\n",
            "d loss: 0.5715, g loss: -0.9633\n",
            "epoch time: 29.5183 [sec]\n",
            "\n",
            "epochs 27\n",
            "steps32\n",
            "d loss: 0.3962, g loss: -0.9153\n",
            "epoch time: 29.5350 [sec]\n",
            "\n",
            "epochs 28\n",
            "steps32\n",
            "d loss: 0.1981, g loss: -0.8779\n",
            "epoch time: 29.5105 [sec]\n",
            "\n",
            "epochs 29\n",
            "steps32\n",
            "d loss: 0.2069, g loss: -0.8415\n",
            "epoch time: 29.5242 [sec]\n",
            "\n",
            "epochs 30\n",
            "steps32\n",
            "d loss: 0.0349, g loss: -0.8159\n",
            "epoch time: 29.5437 [sec]\n",
            "\n",
            "Saving checkpoint at epoch30\n",
            "\n",
            "\n",
            "\n",
            "epochs 31\n",
            "steps32\n",
            "d loss: -0.0868, g loss: -0.7903\n",
            "epoch time: 29.6727 [sec]\n",
            "\n",
            "epochs 32\n",
            "steps32\n",
            "d loss: -0.1068, g loss: -0.7711\n",
            "epoch time: 29.5144 [sec]\n",
            "\n",
            "epochs 33\n",
            "steps32\n",
            "d loss: -0.1868, g loss: -0.7585\n",
            "epoch time: 29.5360 [sec]\n",
            "\n",
            "epochs 34\n",
            "steps32\n",
            "d loss: -0.2688, g loss: -0.7455\n",
            "epoch time: 29.5151 [sec]\n",
            "\n",
            "epochs 35\n",
            "steps32\n",
            "d loss: -0.3807, g loss: -0.7227\n",
            "epoch time: 29.5255 [sec]\n",
            "\n",
            "epochs 36\n",
            "steps32\n",
            "d loss: -0.4344, g loss: -0.7035\n",
            "epoch time: 29.5055 [sec]\n",
            "\n",
            "epochs 37\n",
            "steps32\n",
            "d loss: -0.5477, g loss: -0.6920\n",
            "epoch time: 29.5044 [sec]\n",
            "\n",
            "epochs 38\n",
            "steps32\n",
            "d loss: -0.5305, g loss: -0.6790\n",
            "epoch time: 29.5170 [sec]\n",
            "\n",
            "epochs 39\n",
            "steps32\n",
            "d loss: -0.5976, g loss: -0.6663\n",
            "epoch time: 29.5338 [sec]\n",
            "\n",
            "epochs 40\n",
            "steps32\n",
            "d loss: -0.6872, g loss: -0.6495\n",
            "epoch time: 29.5004 [sec]\n",
            "\n",
            "Saving checkpoint at epoch40\n",
            "\n",
            "\n",
            "\n",
            "epochs 41\n",
            "steps32\n",
            "d loss: -0.7917, g loss: -0.6390\n",
            "epoch time: 29.5490 [sec]\n",
            "\n",
            "epochs 42\n",
            "steps32\n",
            "d loss: -0.8205, g loss: -0.6295\n",
            "epoch time: 29.5341 [sec]\n",
            "\n",
            "epochs 43\n",
            "steps32\n",
            "d loss: -0.8889, g loss: -0.6209\n",
            "epoch time: 29.5551 [sec]\n",
            "\n",
            "epochs 44\n",
            "steps32\n",
            "d loss: -0.9612, g loss: -0.6157\n",
            "epoch time: 29.5388 [sec]\n",
            "\n",
            "epochs 45\n",
            "steps32\n",
            "d loss: -1.0471, g loss: -0.6031\n",
            "epoch time: 29.5316 [sec]\n",
            "\n",
            "epochs 46\n",
            "steps32\n",
            "d loss: -1.0639, g loss: -0.5995\n",
            "epoch time: 29.5212 [sec]\n",
            "\n",
            "epochs 47\n",
            "steps32\n",
            "d loss: -1.0976, g loss: -0.5924\n",
            "epoch time: 29.5080 [sec]\n",
            "\n",
            "epochs 48\n",
            "steps32\n",
            "d loss: -1.2032, g loss: -0.5875\n",
            "epoch time: 29.5430 [sec]\n",
            "\n",
            "epochs 49\n",
            "steps32\n",
            "d loss: -1.2423, g loss: -0.5829\n",
            "epoch time: 29.5192 [sec]\n",
            "\n",
            "epochs 50\n",
            "steps32\n",
            "d loss: -1.2413, g loss: -0.5770\n",
            "epoch time: 29.4975 [sec]\n",
            "\n",
            "Saving checkpoint at epoch50\n",
            "\n",
            "\n",
            "\n",
            "epochs 51\n",
            "steps32\n",
            "d loss: -1.3089, g loss: -0.5712\n",
            "epoch time: 29.5755 [sec]\n",
            "\n",
            "epochs 52\n",
            "steps32\n",
            "d loss: -1.3199, g loss: -0.5727\n",
            "epoch time: 30.4814 [sec]\n",
            "\n",
            "epochs 53\n",
            "steps32\n",
            "d loss: -1.4301, g loss: -0.5640\n",
            "epoch time: 29.5100 [sec]\n",
            "\n",
            "epochs 54\n",
            "steps32\n",
            "d loss: -1.3849, g loss: -0.5613\n",
            "epoch time: 29.4952 [sec]\n",
            "\n",
            "epochs 55\n",
            "steps32\n",
            "d loss: -1.4250, g loss: -0.5557\n",
            "epoch time: 29.5170 [sec]\n",
            "\n",
            "epochs 56\n",
            "steps32\n",
            "d loss: -1.5202, g loss: -0.5556\n",
            "epoch time: 29.5101 [sec]\n",
            "\n",
            "epochs 57\n",
            "steps32\n",
            "d loss: -1.4761, g loss: -0.5542\n",
            "epoch time: 29.5302 [sec]\n",
            "\n",
            "epochs 58\n",
            "steps32\n",
            "d loss: -1.4992, g loss: -0.5554\n",
            "epoch time: 29.5037 [sec]\n",
            "\n",
            "epochs 59\n",
            "steps32\n",
            "d loss: -1.5392, g loss: -0.5532\n",
            "epoch time: 29.5594 [sec]\n",
            "\n",
            "epochs 60\n",
            "steps32\n",
            "d loss: -1.5259, g loss: -0.5606\n",
            "epoch time: 29.5100 [sec]\n",
            "\n",
            "Saving checkpoint at epoch60\n",
            "\n",
            "\n",
            "\n",
            "epochs 61\n",
            "steps32\n",
            "d loss: -1.5117, g loss: -0.5602\n",
            "epoch time: 29.6941 [sec]\n",
            "\n",
            "epochs 62\n",
            "steps32\n",
            "d loss: -1.4050, g loss: -0.5622\n",
            "epoch time: 29.5102 [sec]\n",
            "\n",
            "epochs 63\n",
            "steps32\n",
            "d loss: -1.4488, g loss: -0.5616\n",
            "epoch time: 29.5419 [sec]\n",
            "\n",
            "epochs 64\n",
            "steps32\n",
            "d loss: -1.4089, g loss: -0.5622\n",
            "epoch time: 29.5291 [sec]\n",
            "\n",
            "epochs 65\n",
            "steps32\n",
            "d loss: -1.4015, g loss: -0.5644\n",
            "epoch time: 29.5143 [sec]\n",
            "\n",
            "epochs 66\n",
            "steps32\n",
            "d loss: -1.3962, g loss: -0.5633\n",
            "epoch time: 29.5338 [sec]\n",
            "\n",
            "epochs 67\n",
            "steps32\n",
            "d loss: -1.3461, g loss: -0.5686\n",
            "epoch time: 29.5534 [sec]\n",
            "\n",
            "epochs 68\n",
            "steps32\n",
            "d loss: -1.2675, g loss: -0.5704\n",
            "epoch time: 29.5168 [sec]\n",
            "\n",
            "epochs 69\n",
            "steps32\n",
            "d loss: -1.2078, g loss: -0.5732\n",
            "epoch time: 29.5314 [sec]\n",
            "\n",
            "epochs 70\n",
            "steps32\n",
            "d loss: -1.2042, g loss: -0.5767\n",
            "epoch time: 29.5998 [sec]\n",
            "\n",
            "Saving checkpoint at epoch70\n",
            "\n",
            "\n",
            "\n",
            "epochs 71\n",
            "steps32\n",
            "d loss: -1.1201, g loss: -0.5775\n",
            "epoch time: 29.6010 [sec]\n",
            "\n",
            "epochs 72\n",
            "steps32\n",
            "d loss: -1.0318, g loss: -0.5871\n",
            "epoch time: 29.5683 [sec]\n",
            "\n",
            "epochs 73\n",
            "steps32\n",
            "d loss: -0.9747, g loss: -0.5998\n",
            "epoch time: 29.5889 [sec]\n",
            "\n",
            "epochs 74\n",
            "steps32\n",
            "d loss: -0.8537, g loss: -0.6125\n",
            "epoch time: 29.5585 [sec]\n",
            "\n",
            "epochs 75\n",
            "steps32\n",
            "d loss: -0.6743, g loss: -0.6287\n",
            "epoch time: 29.5903 [sec]\n",
            "\n",
            "epochs 76\n",
            "steps32\n",
            "d loss: -0.5821, g loss: -0.6476\n",
            "epoch time: 29.5860 [sec]\n",
            "\n",
            "epochs 77\n",
            "steps32\n",
            "d loss: -0.4309, g loss: -0.6674\n",
            "epoch time: 29.5748 [sec]\n",
            "\n",
            "epochs 78\n",
            "steps32\n",
            "d loss: -0.2891, g loss: -0.6857\n",
            "epoch time: 29.5940 [sec]\n",
            "\n",
            "epochs 79\n",
            "steps32\n",
            "d loss: -0.2017, g loss: -0.6948\n",
            "epoch time: 29.5819 [sec]\n",
            "\n",
            "epochs 80\n",
            "steps32\n",
            "d loss: -0.1231, g loss: -0.6964\n",
            "epoch time: 29.5750 [sec]\n",
            "\n",
            "Saving checkpoint at epoch80\n",
            "\n",
            "\n",
            "\n",
            "epochs 81\n",
            "steps32\n",
            "d loss: -0.0827, g loss: -0.7046\n",
            "epoch time: 29.6651 [sec]\n",
            "\n",
            "epochs 82\n",
            "steps32\n",
            "d loss: -0.0134, g loss: -0.6968\n",
            "epoch time: 29.5135 [sec]\n",
            "\n",
            "epochs 83\n",
            "steps32\n",
            "d loss: 0.0501, g loss: -0.6844\n",
            "epoch time: 29.5405 [sec]\n",
            "\n",
            "epochs 84\n",
            "steps32\n",
            "d loss: 0.0590, g loss: -0.6702\n",
            "epoch time: 29.5341 [sec]\n",
            "\n",
            "epochs 85\n",
            "steps32\n",
            "d loss: 0.0034, g loss: -0.6612\n",
            "epoch time: 29.5057 [sec]\n",
            "\n",
            "epochs 86\n",
            "steps32\n",
            "d loss: -0.0950, g loss: -0.6442\n",
            "epoch time: 29.5104 [sec]\n",
            "\n",
            "epochs 87\n",
            "steps32\n",
            "d loss: -0.0301, g loss: -0.6271\n",
            "epoch time: 29.5448 [sec]\n",
            "\n",
            "epochs 88\n",
            "steps32\n",
            "d loss: -0.1380, g loss: -0.6116\n",
            "epoch time: 29.5331 [sec]\n",
            "\n",
            "epochs 89\n",
            "steps32\n",
            "d loss: -0.1468, g loss: -0.5968\n",
            "epoch time: 29.5090 [sec]\n",
            "\n",
            "epochs 90\n",
            "steps32\n",
            "d loss: -0.1777, g loss: -0.5768\n",
            "epoch time: 29.5111 [sec]\n",
            "\n",
            "Saving checkpoint at epoch90\n",
            "\n",
            "\n",
            "\n",
            "epochs 91\n",
            "steps32\n",
            "d loss: -0.1698, g loss: -0.5708\n",
            "epoch time: 29.5760 [sec]\n",
            "\n",
            "epochs 92\n",
            "steps32\n",
            "d loss: -0.1966, g loss: -0.5508\n",
            "epoch time: 29.5146 [sec]\n",
            "\n",
            "epochs 93\n",
            "steps32\n",
            "d loss: -0.2370, g loss: -0.5419\n",
            "epoch time: 29.4954 [sec]\n",
            "\n",
            "epochs 94\n",
            "steps32\n",
            "d loss: -0.2369, g loss: -0.5221\n",
            "epoch time: 29.5024 [sec]\n",
            "\n",
            "epochs 95\n",
            "steps32\n",
            "d loss: -0.1854, g loss: -0.5121\n",
            "epoch time: 29.5262 [sec]\n",
            "\n",
            "epochs 96\n",
            "steps32\n",
            "d loss: -0.1824, g loss: -0.4962\n",
            "epoch time: 29.5004 [sec]\n",
            "\n",
            "epochs 97\n",
            "steps32\n",
            "d loss: -0.2309, g loss: -0.4816\n",
            "epoch time: 29.5320 [sec]\n",
            "\n",
            "epochs 98\n",
            "steps32\n",
            "d loss: -0.2648, g loss: -0.4637\n",
            "epoch time: 29.5293 [sec]\n",
            "\n",
            "epochs 99\n",
            "steps32\n",
            "d loss: -0.2964, g loss: -0.4453\n",
            "epoch time: 29.5758 [sec]\n",
            "\n",
            "epochs 100\n",
            "steps32\n",
            "d loss: -0.2954, g loss: -0.4300\n",
            "epoch time: 29.5088 [sec]\n",
            "\n",
            "Saving checkpoint at epoch100\n",
            "\n",
            "\n",
            "\n",
            "epochs 101\n",
            "steps32\n",
            "d loss: -0.2426, g loss: -0.4052\n",
            "epoch time: 29.6143 [sec]\n",
            "\n",
            "epochs 102\n",
            "steps32\n",
            "d loss: -0.3403, g loss: -0.3873\n",
            "epoch time: 29.5720 [sec]\n",
            "\n",
            "epochs 103\n",
            "steps32\n",
            "d loss: -0.2800, g loss: -0.3591\n",
            "epoch time: 29.5592 [sec]\n",
            "\n",
            "epochs 104\n",
            "steps32\n",
            "d loss: -0.2712, g loss: -0.3367\n",
            "epoch time: 29.5140 [sec]\n",
            "\n",
            "epochs 105\n",
            "steps32\n",
            "d loss: -0.3215, g loss: -0.3157\n",
            "epoch time: 29.5351 [sec]\n",
            "\n",
            "epochs 106\n",
            "steps32\n",
            "d loss: -0.3038, g loss: -0.2907\n",
            "epoch time: 29.5313 [sec]\n",
            "\n",
            "epochs 107\n",
            "steps32\n",
            "d loss: -0.3674, g loss: -0.2624\n",
            "epoch time: 29.5285 [sec]\n",
            "\n",
            "epochs 108\n",
            "steps32\n",
            "d loss: -0.3529, g loss: -0.2370\n",
            "epoch time: 29.5454 [sec]\n",
            "\n",
            "epochs 109\n",
            "steps32\n",
            "d loss: -0.3476, g loss: -0.2125\n",
            "epoch time: 29.4952 [sec]\n",
            "\n",
            "epochs 110\n",
            "steps32\n",
            "d loss: -0.3542, g loss: -0.1777\n",
            "epoch time: 29.5440 [sec]\n",
            "\n",
            "Saving checkpoint at epoch110\n",
            "\n",
            "\n",
            "\n",
            "epochs 111\n",
            "steps32\n",
            "d loss: -0.3987, g loss: -0.1537\n",
            "epoch time: 29.5609 [sec]\n",
            "\n",
            "epochs 112\n",
            "steps32\n",
            "d loss: -0.4198, g loss: -0.1291\n",
            "epoch time: 29.5189 [sec]\n",
            "\n",
            "epochs 113\n",
            "steps32\n",
            "d loss: -0.4769, g loss: -0.1046\n",
            "epoch time: 29.5023 [sec]\n",
            "\n",
            "epochs 114\n",
            "steps32\n",
            "d loss: -0.4687, g loss: -0.0821\n",
            "epoch time: 29.5163 [sec]\n",
            "\n",
            "epochs 115\n",
            "steps32\n",
            "d loss: -0.4472, g loss: -0.0615\n",
            "epoch time: 29.5156 [sec]\n",
            "\n",
            "epochs 116\n",
            "steps32\n",
            "d loss: -0.4515, g loss: -0.0370\n",
            "epoch time: 29.4998 [sec]\n",
            "\n",
            "epochs 117\n",
            "steps32\n",
            "d loss: -0.4584, g loss: -0.0158\n",
            "epoch time: 29.5127 [sec]\n",
            "\n",
            "epochs 118\n",
            "steps32\n",
            "d loss: -0.4380, g loss: 0.0074\n",
            "epoch time: 29.5077 [sec]\n",
            "\n",
            "epochs 119\n",
            "steps32\n",
            "d loss: -0.5230, g loss: 0.0288\n",
            "epoch time: 29.5005 [sec]\n",
            "\n",
            "epochs 120\n",
            "steps32\n",
            "d loss: -0.5171, g loss: 0.0463\n",
            "epoch time: 29.5123 [sec]\n",
            "\n",
            "Saving checkpoint at epoch120\n",
            "\n",
            "\n",
            "\n",
            "epochs 121\n",
            "steps32\n",
            "d loss: -0.5580, g loss: 0.0689\n",
            "epoch time: 29.6637 [sec]\n",
            "\n",
            "epochs 122\n",
            "steps32\n",
            "d loss: -0.6353, g loss: 0.0880\n",
            "epoch time: 29.5317 [sec]\n",
            "\n",
            "epochs 123\n",
            "steps32\n",
            "d loss: -0.6647, g loss: 0.1100\n",
            "epoch time: 29.5269 [sec]\n",
            "\n",
            "epochs 124\n",
            "steps32\n",
            "d loss: -0.6425, g loss: 0.1383\n",
            "epoch time: 29.5220 [sec]\n",
            "\n",
            "epochs 125\n",
            "steps32\n",
            "d loss: -0.7449, g loss: 0.1545\n",
            "epoch time: 29.5137 [sec]\n",
            "\n",
            "epochs 126\n",
            "steps32\n",
            "d loss: -0.7630, g loss: 0.1755\n",
            "epoch time: 29.5183 [sec]\n",
            "\n",
            "epochs 127\n",
            "steps32\n",
            "d loss: -0.7433, g loss: 0.1974\n",
            "epoch time: 29.5249 [sec]\n",
            "\n",
            "epochs 128\n",
            "steps32\n",
            "d loss: -0.7698, g loss: 0.2177\n",
            "epoch time: 29.5020 [sec]\n",
            "\n",
            "epochs 129\n",
            "steps32\n",
            "d loss: -0.8233, g loss: 0.2382\n",
            "epoch time: 29.5315 [sec]\n",
            "\n",
            "epochs 130\n",
            "steps32\n",
            "d loss: -0.8949, g loss: 0.2604\n",
            "epoch time: 29.5152 [sec]\n",
            "\n",
            "Saving checkpoint at epoch130\n",
            "\n",
            "\n",
            "\n",
            "epochs 131\n",
            "steps32\n",
            "d loss: -0.8942, g loss: 0.2785\n",
            "epoch time: 29.5725 [sec]\n",
            "\n",
            "epochs 132\n",
            "steps32\n",
            "d loss: -0.9371, g loss: 0.2961\n",
            "epoch time: 29.5115 [sec]\n",
            "\n",
            "epochs 133\n",
            "steps32\n",
            "d loss: -0.9594, g loss: 0.3152\n",
            "epoch time: 29.5398 [sec]\n",
            "\n",
            "epochs 134\n",
            "steps32\n",
            "d loss: -0.9170, g loss: 0.3331\n",
            "epoch time: 29.5791 [sec]\n",
            "\n",
            "epochs 135\n",
            "steps32\n",
            "d loss: -0.9612, g loss: 0.3564\n",
            "epoch time: 29.5207 [sec]\n",
            "\n",
            "epochs 136\n",
            "steps32\n",
            "d loss: -1.0638, g loss: 0.3766\n",
            "epoch time: 29.5292 [sec]\n",
            "\n",
            "epochs 137\n",
            "steps32\n",
            "d loss: -1.0395, g loss: 0.3858\n",
            "epoch time: 29.5125 [sec]\n",
            "\n",
            "epochs 138\n",
            "steps32\n",
            "d loss: -1.0311, g loss: 0.4019\n",
            "epoch time: 29.5226 [sec]\n",
            "\n",
            "epochs 139\n",
            "steps32\n",
            "d loss: -1.0067, g loss: 0.4193\n",
            "epoch time: 29.5639 [sec]\n",
            "\n",
            "epochs 140\n",
            "steps32\n",
            "d loss: -1.0265, g loss: 0.4385\n",
            "epoch time: 29.5372 [sec]\n",
            "\n",
            "Saving checkpoint at epoch140\n",
            "\n",
            "\n",
            "\n",
            "epochs 141\n",
            "steps32\n",
            "d loss: -1.0853, g loss: 0.4537\n",
            "epoch time: 29.6189 [sec]\n",
            "\n",
            "epochs 142\n",
            "steps32\n",
            "d loss: -1.1323, g loss: 0.4711\n",
            "epoch time: 29.5402 [sec]\n",
            "\n",
            "epochs 143\n",
            "steps32\n",
            "d loss: -1.0716, g loss: 0.4869\n",
            "epoch time: 29.5533 [sec]\n",
            "\n",
            "epochs 144\n",
            "steps32\n",
            "d loss: -1.0728, g loss: 0.5060\n",
            "epoch time: 29.5309 [sec]\n",
            "\n",
            "epochs 145\n",
            "steps32\n",
            "d loss: -1.0816, g loss: 0.5231\n",
            "epoch time: 29.5182 [sec]\n",
            "\n",
            "epochs 146\n",
            "steps32\n",
            "d loss: -1.0807, g loss: 0.5363\n",
            "epoch time: 29.5448 [sec]\n",
            "\n",
            "epochs 147\n",
            "steps32\n",
            "d loss: -1.1004, g loss: 0.5499\n",
            "epoch time: 29.5108 [sec]\n",
            "\n",
            "epochs 148\n",
            "steps32\n",
            "d loss: -1.1542, g loss: 0.5647\n",
            "epoch time: 29.5143 [sec]\n",
            "\n",
            "epochs 149\n",
            "steps32\n",
            "d loss: -1.1255, g loss: 0.5773\n",
            "epoch time: 29.5181 [sec]\n",
            "\n",
            "epochs 150\n",
            "steps32\n",
            "d loss: -1.1268, g loss: 0.5910\n",
            "epoch time: 29.5084 [sec]\n",
            "\n",
            "Saving checkpoint at epoch150\n",
            "\n",
            "\n",
            "\n",
            "epochs 151\n",
            "steps32\n",
            "d loss: -1.1390, g loss: 0.6024\n",
            "epoch time: 29.5838 [sec]\n",
            "\n",
            "epochs 152\n",
            "steps32\n",
            "d loss: -1.1438, g loss: 0.6155\n",
            "epoch time: 29.4870 [sec]\n",
            "\n",
            "epochs 153\n",
            "steps32\n",
            "d loss: -1.1108, g loss: 0.6244\n",
            "epoch time: 29.5487 [sec]\n",
            "\n",
            "epochs 154\n",
            "steps32\n",
            "d loss: -1.0927, g loss: 0.6348\n",
            "epoch time: 29.5870 [sec]\n",
            "\n",
            "epochs 155\n",
            "steps32\n",
            "d loss: -1.0989, g loss: 0.6443\n",
            "epoch time: 29.5310 [sec]\n",
            "\n",
            "epochs 156\n",
            "steps32\n",
            "d loss: -1.1591, g loss: 0.6514\n",
            "epoch time: 29.6174 [sec]\n",
            "\n",
            "epochs 157\n",
            "steps32\n",
            "d loss: -1.1217, g loss: 0.6666\n",
            "epoch time: 29.5526 [sec]\n",
            "\n",
            "epochs 158\n",
            "steps32\n",
            "d loss: -1.1497, g loss: 0.6770\n",
            "epoch time: 29.5555 [sec]\n",
            "\n",
            "epochs 159\n",
            "steps32\n",
            "d loss: -1.1099, g loss: 0.6829\n",
            "epoch time: 29.6053 [sec]\n",
            "\n",
            "epochs 160\n",
            "steps32\n",
            "d loss: -1.0681, g loss: 0.6936\n",
            "epoch time: 29.5318 [sec]\n",
            "\n",
            "Saving checkpoint at epoch160\n",
            "\n",
            "\n",
            "\n",
            "epochs 161\n",
            "steps32\n",
            "d loss: -1.1023, g loss: 0.7058\n",
            "epoch time: 29.5539 [sec]\n",
            "\n",
            "epochs 162\n",
            "steps32\n",
            "d loss: -1.1893, g loss: 0.7162\n",
            "epoch time: 29.5492 [sec]\n",
            "\n",
            "epochs 163\n",
            "steps32\n",
            "d loss: -1.1534, g loss: 0.7331\n",
            "epoch time: 29.4848 [sec]\n",
            "\n",
            "epochs 164\n",
            "steps32\n",
            "d loss: -1.1555, g loss: 0.7387\n",
            "epoch time: 29.5364 [sec]\n",
            "\n",
            "epochs 165\n",
            "steps32\n",
            "d loss: -1.1466, g loss: 0.7533\n",
            "epoch time: 29.4855 [sec]\n",
            "\n",
            "epochs 166\n",
            "steps32\n",
            "d loss: -1.0632, g loss: 0.7657\n",
            "epoch time: 29.4748 [sec]\n",
            "\n",
            "epochs 167\n",
            "steps32\n",
            "d loss: -1.1538, g loss: 0.7730\n",
            "epoch time: 29.5360 [sec]\n",
            "\n",
            "epochs 168\n",
            "steps32\n",
            "d loss: -1.2165, g loss: 0.7888\n",
            "epoch time: 29.5293 [sec]\n",
            "\n",
            "epochs 169\n",
            "steps32\n",
            "d loss: -1.1716, g loss: 0.7977\n",
            "epoch time: 29.5060 [sec]\n",
            "\n",
            "epochs 170\n",
            "steps32\n",
            "d loss: -1.1648, g loss: 0.8044\n",
            "epoch time: 29.5001 [sec]\n",
            "\n",
            "Saving checkpoint at epoch170\n",
            "\n",
            "\n",
            "\n",
            "epochs 171\n",
            "steps32\n",
            "d loss: -1.1529, g loss: 0.8127\n",
            "epoch time: 29.5744 [sec]\n",
            "\n",
            "epochs 172\n",
            "steps32\n",
            "d loss: -1.2162, g loss: 0.8226\n",
            "epoch time: 29.5291 [sec]\n",
            "\n",
            "epochs 173\n",
            "steps32\n",
            "d loss: -1.2100, g loss: 0.8335\n",
            "epoch time: 29.5096 [sec]\n",
            "\n",
            "epochs 174\n",
            "steps32\n",
            "d loss: -1.1667, g loss: 0.8477\n",
            "epoch time: 29.5303 [sec]\n",
            "\n",
            "epochs 175\n",
            "steps32\n",
            "d loss: -1.2095, g loss: 0.8588\n",
            "epoch time: 29.5053 [sec]\n",
            "\n",
            "epochs 176\n",
            "steps32\n",
            "d loss: -1.1727, g loss: 0.8723\n",
            "epoch time: 29.4985 [sec]\n",
            "\n",
            "epochs 177\n",
            "steps32\n",
            "d loss: -1.2583, g loss: 0.8793\n",
            "epoch time: 29.5516 [sec]\n",
            "\n",
            "epochs 178\n",
            "steps32\n",
            "d loss: -1.3046, g loss: 0.8936\n",
            "epoch time: 29.5439 [sec]\n",
            "\n",
            "epochs 179\n",
            "steps32\n",
            "d loss: -1.2411, g loss: 0.9033\n",
            "epoch time: 29.5195 [sec]\n",
            "\n",
            "epochs 180\n",
            "steps32\n",
            "d loss: -1.2721, g loss: 0.9117\n",
            "epoch time: 29.5168 [sec]\n",
            "\n",
            "Saving checkpoint at epoch180\n",
            "\n",
            "\n",
            "\n",
            "epochs 181\n",
            "steps32\n",
            "d loss: -1.2760, g loss: 0.9290\n",
            "epoch time: 29.5405 [sec]\n",
            "\n",
            "epochs 182\n",
            "steps32\n",
            "d loss: -1.2154, g loss: 0.9369\n",
            "epoch time: 29.5057 [sec]\n",
            "\n",
            "epochs 183\n",
            "steps32\n",
            "d loss: -1.3115, g loss: 0.9541\n",
            "epoch time: 29.5252 [sec]\n",
            "\n",
            "epochs 184\n",
            "steps32\n",
            "d loss: -1.2555, g loss: 0.9680\n",
            "epoch time: 29.5573 [sec]\n",
            "\n",
            "epochs 185\n",
            "steps32\n",
            "d loss: -1.2606, g loss: 0.9808\n",
            "epoch time: 29.5340 [sec]\n",
            "\n",
            "epochs 186\n",
            "steps32\n",
            "d loss: -1.3544, g loss: 0.9947\n",
            "epoch time: 29.5521 [sec]\n",
            "\n",
            "epochs 187\n",
            "steps32\n",
            "d loss: -1.2655, g loss: 1.0077\n",
            "epoch time: 29.5313 [sec]\n",
            "\n",
            "epochs 188\n",
            "steps32\n",
            "d loss: -1.3814, g loss: 1.0248\n",
            "epoch time: 29.5314 [sec]\n",
            "\n",
            "epochs 189\n",
            "steps32\n",
            "d loss: -1.3506, g loss: 1.0374\n",
            "epoch time: 29.5083 [sec]\n",
            "\n",
            "epochs 190\n",
            "steps32\n",
            "d loss: -1.3433, g loss: 1.0565\n",
            "epoch time: 29.4948 [sec]\n",
            "\n",
            "Saving checkpoint at epoch190\n",
            "\n",
            "\n",
            "\n",
            "epochs 191\n",
            "steps32\n",
            "d loss: -1.3577, g loss: 1.0680\n",
            "epoch time: 29.5939 [sec]\n",
            "\n",
            "epochs 192\n",
            "steps32\n",
            "d loss: -1.3109, g loss: 1.0851\n",
            "epoch time: 29.5132 [sec]\n",
            "\n",
            "epochs 193\n",
            "steps32\n",
            "d loss: -1.4092, g loss: 1.0999\n",
            "epoch time: 29.5239 [sec]\n",
            "\n",
            "epochs 194\n",
            "steps32\n",
            "d loss: -1.3178, g loss: 1.1167\n",
            "epoch time: 29.5291 [sec]\n",
            "\n",
            "epochs 195\n",
            "steps32\n",
            "d loss: -1.3965, g loss: 1.1327\n",
            "epoch time: 29.5250 [sec]\n",
            "\n",
            "epochs 196\n",
            "steps32\n",
            "d loss: -1.4091, g loss: 1.1509\n",
            "epoch time: 29.5754 [sec]\n",
            "\n",
            "epochs 197\n",
            "steps32\n",
            "d loss: -1.3951, g loss: 1.1662\n",
            "epoch time: 29.5382 [sec]\n",
            "\n",
            "epochs 198\n",
            "steps32\n",
            "d loss: -1.3618, g loss: 1.1815\n",
            "epoch time: 29.5775 [sec]\n",
            "\n",
            "epochs 199\n",
            "steps32\n",
            "d loss: -1.3385, g loss: 1.2012\n",
            "epoch time: 29.5263 [sec]\n",
            "\n",
            "epochs 200\n",
            "steps32\n",
            "d loss: -1.4069, g loss: 1.2159\n",
            "epoch time: 29.5528 [sec]\n",
            "\n",
            "Saving checkpoint at epoch200\n",
            "\n",
            "\n",
            "\n",
            "epochs 201\n",
            "steps32\n",
            "d loss: -1.4425, g loss: 1.2375\n",
            "epoch time: 29.5406 [sec]\n",
            "\n",
            "epochs 202\n",
            "steps32\n",
            "d loss: -1.5166, g loss: 1.2542\n",
            "epoch time: 29.5830 [sec]\n",
            "\n",
            "epochs 203\n",
            "steps32\n",
            "d loss: -1.4199, g loss: 1.2717\n",
            "epoch time: 29.5458 [sec]\n",
            "\n",
            "epochs 204\n",
            "steps32\n",
            "d loss: -1.4753, g loss: 1.2938\n",
            "epoch time: 29.5272 [sec]\n",
            "\n",
            "epochs 205\n",
            "steps32\n",
            "d loss: -1.4323, g loss: 1.3125\n",
            "epoch time: 29.5342 [sec]\n",
            "\n",
            "epochs 206\n",
            "steps32\n",
            "d loss: -1.4317, g loss: 1.3327\n",
            "epoch time: 29.5327 [sec]\n",
            "\n",
            "epochs 207\n",
            "steps32\n",
            "d loss: -1.4589, g loss: 1.3514\n",
            "epoch time: 29.5457 [sec]\n",
            "\n",
            "epochs 208\n",
            "steps32\n",
            "d loss: -1.4196, g loss: 1.3694\n",
            "epoch time: 29.5596 [sec]\n",
            "\n",
            "epochs 209\n",
            "steps32\n",
            "d loss: -1.4744, g loss: 1.3900\n",
            "epoch time: 29.5084 [sec]\n",
            "\n",
            "epochs 210\n",
            "steps32\n",
            "d loss: -1.4431, g loss: 1.4075\n",
            "epoch time: 29.5132 [sec]\n",
            "\n",
            "Saving checkpoint at epoch210\n",
            "\n",
            "\n",
            "\n",
            "epochs 211\n",
            "steps32\n",
            "d loss: -1.5360, g loss: 1.4300\n",
            "epoch time: 29.5502 [sec]\n",
            "\n",
            "epochs 212\n",
            "steps32\n",
            "d loss: -1.4335, g loss: 1.4485\n",
            "epoch time: 29.5129 [sec]\n",
            "\n",
            "epochs 213\n",
            "steps32\n",
            "d loss: -1.4985, g loss: 1.4655\n",
            "epoch time: 29.5540 [sec]\n",
            "\n",
            "epochs 214\n",
            "steps32\n",
            "d loss: -1.4711, g loss: 1.4862\n",
            "epoch time: 29.5458 [sec]\n",
            "\n",
            "epochs 215\n",
            "steps32\n",
            "d loss: -1.5976, g loss: 1.5056\n",
            "epoch time: 29.5266 [sec]\n",
            "\n",
            "epochs 216\n",
            "steps32\n",
            "d loss: -1.4408, g loss: 1.5224\n",
            "epoch time: 29.5009 [sec]\n",
            "\n",
            "epochs 217\n",
            "steps32\n",
            "d loss: -1.5272, g loss: 1.5403\n",
            "epoch time: 29.6241 [sec]\n",
            "\n",
            "epochs 218\n",
            "steps32\n",
            "d loss: -1.5228, g loss: 1.5555\n",
            "epoch time: 29.6365 [sec]\n",
            "\n",
            "epochs 219\n",
            "steps32\n",
            "d loss: -1.5023, g loss: 1.5771\n",
            "epoch time: 29.5227 [sec]\n",
            "\n",
            "epochs 220\n",
            "steps32\n",
            "d loss: -1.4831, g loss: 1.5956\n",
            "epoch time: 29.5336 [sec]\n",
            "\n",
            "Saving checkpoint at epoch220\n",
            "\n",
            "\n",
            "\n",
            "epochs 221\n",
            "steps32\n",
            "d loss: -1.5137, g loss: 1.6233\n",
            "epoch time: 33.3407 [sec]\n",
            "\n",
            "epochs 222\n",
            "steps32\n",
            "d loss: -1.5614, g loss: 1.6423\n",
            "epoch time: 29.5634 [sec]\n",
            "\n",
            "epochs 223\n",
            "steps32\n",
            "d loss: -1.5482, g loss: 1.6555\n",
            "epoch time: 29.5475 [sec]\n",
            "\n",
            "epochs 224\n",
            "steps32\n",
            "d loss: -1.5778, g loss: 1.6737\n",
            "epoch time: 29.5465 [sec]\n",
            "\n",
            "epochs 225\n",
            "steps32\n",
            "d loss: -1.6051, g loss: 1.6900\n",
            "epoch time: 29.5413 [sec]\n",
            "\n",
            "epochs 226\n",
            "steps32\n",
            "d loss: -1.5360, g loss: 1.7072\n",
            "epoch time: 29.5534 [sec]\n",
            "\n",
            "epochs 227\n",
            "steps32\n",
            "d loss: -1.5899, g loss: 1.7246\n",
            "epoch time: 29.5408 [sec]\n",
            "\n",
            "epochs 228\n",
            "steps32\n",
            "d loss: -1.5600, g loss: 1.7429\n",
            "epoch time: 29.5305 [sec]\n",
            "\n",
            "epochs 229\n",
            "steps32\n",
            "d loss: -1.5603, g loss: 1.7611\n",
            "epoch time: 29.5531 [sec]\n",
            "\n",
            "epochs 230\n",
            "steps32\n",
            "d loss: -1.6006, g loss: 1.7826\n",
            "epoch time: 29.5493 [sec]\n",
            "\n",
            "Saving checkpoint at epoch230\n",
            "\n",
            "\n",
            "\n",
            "epochs 231\n",
            "steps32\n",
            "d loss: -1.6231, g loss: 1.8048\n",
            "epoch time: 29.5367 [sec]\n",
            "\n",
            "epochs 232\n",
            "steps32\n",
            "d loss: -1.5795, g loss: 1.8207\n",
            "epoch time: 29.5451 [sec]\n",
            "\n",
            "epochs 233\n",
            "steps32\n",
            "d loss: -1.5886, g loss: 1.8395\n",
            "epoch time: 29.5223 [sec]\n",
            "\n",
            "epochs 234\n",
            "steps32\n",
            "d loss: -1.6089, g loss: 1.8592\n",
            "epoch time: 29.5695 [sec]\n",
            "\n",
            "epochs 235\n",
            "steps32\n",
            "d loss: -1.5278, g loss: 1.8683\n",
            "epoch time: 29.6110 [sec]\n",
            "\n",
            "epochs 236\n",
            "steps32\n",
            "d loss: -1.5916, g loss: 1.8877\n",
            "epoch time: 29.5256 [sec]\n",
            "\n",
            "epochs 237\n",
            "steps32\n",
            "d loss: -1.5963, g loss: 1.9036\n",
            "epoch time: 29.5047 [sec]\n",
            "\n",
            "epochs 238\n",
            "steps32\n",
            "d loss: -1.5953, g loss: 1.9233\n",
            "epoch time: 29.5144 [sec]\n",
            "\n",
            "epochs 239\n",
            "steps32\n",
            "d loss: -1.6053, g loss: 1.9434\n",
            "epoch time: 29.5062 [sec]\n",
            "\n",
            "epochs 240\n",
            "steps32\n",
            "d loss: -1.5661, g loss: 1.9533\n",
            "epoch time: 29.5448 [sec]\n",
            "\n",
            "Saving checkpoint at epoch240\n",
            "\n",
            "\n",
            "\n",
            "epochs 241\n",
            "steps32\n",
            "d loss: -1.5668, g loss: 1.9745\n",
            "epoch time: 29.5654 [sec]\n",
            "\n",
            "epochs 242\n",
            "steps32\n",
            "d loss: -1.6214, g loss: 1.9966\n",
            "epoch time: 29.5202 [sec]\n",
            "\n",
            "epochs 243\n",
            "steps32\n",
            "d loss: -1.6041, g loss: 2.0105\n",
            "epoch time: 29.5455 [sec]\n",
            "\n",
            "epochs 244\n",
            "steps32\n",
            "d loss: -1.6047, g loss: 2.0266\n",
            "epoch time: 29.7223 [sec]\n",
            "\n",
            "epochs 245\n",
            "steps32\n",
            "d loss: -1.6241, g loss: 2.0490\n",
            "epoch time: 29.5589 [sec]\n",
            "\n",
            "epochs 246\n",
            "steps32\n",
            "d loss: -1.6209, g loss: 2.0617\n",
            "epoch time: 29.5133 [sec]\n",
            "\n",
            "epochs 247\n",
            "steps32\n",
            "d loss: -1.6401, g loss: 2.0744\n",
            "epoch time: 29.5035 [sec]\n",
            "\n",
            "epochs 248\n",
            "steps32\n",
            "d loss: -1.6186, g loss: 2.0949\n",
            "epoch time: 29.5412 [sec]\n",
            "\n",
            "epochs 249\n",
            "steps32\n",
            "d loss: -1.6590, g loss: 2.1089\n",
            "epoch time: 29.5397 [sec]\n",
            "\n",
            "epochs 250\n",
            "steps32\n",
            "d loss: -1.6098, g loss: 2.1294\n",
            "epoch time: 29.5317 [sec]\n",
            "\n",
            "Saving checkpoint at epoch250\n",
            "\n",
            "\n",
            "\n",
            "epochs 251\n",
            "steps32\n",
            "d loss: -1.6220, g loss: 2.1488\n",
            "epoch time: 29.5988 [sec]\n",
            "\n",
            "epochs 252\n",
            "steps32\n",
            "d loss: -1.6112, g loss: 2.1621\n",
            "epoch time: 29.5766 [sec]\n",
            "\n",
            "epochs 253\n",
            "steps32\n",
            "d loss: -1.6679, g loss: 2.1804\n",
            "epoch time: 29.5234 [sec]\n",
            "\n",
            "epochs 254\n",
            "steps32\n",
            "d loss: -1.6186, g loss: 2.2011\n",
            "epoch time: 29.5371 [sec]\n",
            "\n",
            "epochs 255\n",
            "steps32\n",
            "d loss: -1.6399, g loss: 2.2191\n",
            "epoch time: 29.5118 [sec]\n",
            "\n",
            "epochs 256\n",
            "steps32\n",
            "d loss: -1.5283, g loss: 2.2319\n",
            "epoch time: 29.5681 [sec]\n",
            "\n",
            "epochs 257\n",
            "steps32\n",
            "d loss: -1.6139, g loss: 2.2527\n",
            "epoch time: 29.5472 [sec]\n",
            "\n",
            "epochs 258\n",
            "steps32\n",
            "d loss: -1.6593, g loss: 2.2659\n",
            "epoch time: 29.5225 [sec]\n",
            "\n",
            "epochs 259\n",
            "steps32\n",
            "d loss: -1.6285, g loss: 2.2824\n",
            "epoch time: 29.5037 [sec]\n",
            "\n",
            "epochs 260\n",
            "steps32\n",
            "d loss: -1.7052, g loss: 2.3070\n",
            "epoch time: 29.5548 [sec]\n",
            "\n",
            "Saving checkpoint at epoch260\n",
            "\n",
            "\n",
            "\n",
            "epochs 261\n",
            "steps32\n",
            "d loss: -1.6190, g loss: 2.3251\n",
            "epoch time: 29.5527 [sec]\n",
            "\n",
            "epochs 262\n",
            "steps32\n",
            "d loss: -1.5818, g loss: 2.3475\n",
            "epoch time: 29.5179 [sec]\n",
            "\n",
            "epochs 263\n",
            "steps32\n",
            "d loss: -1.5605, g loss: 2.3583\n",
            "epoch time: 29.5872 [sec]\n",
            "\n",
            "epochs 264\n",
            "steps32\n",
            "d loss: -1.5861, g loss: 2.3774\n",
            "epoch time: 29.6212 [sec]\n",
            "\n",
            "epochs 265\n",
            "steps32\n",
            "d loss: -1.6062, g loss: 2.3933\n",
            "epoch time: 29.6842 [sec]\n",
            "\n",
            "epochs 266\n",
            "steps32\n",
            "d loss: -1.5710, g loss: 2.4132\n",
            "epoch time: 29.5514 [sec]\n",
            "\n",
            "epochs 267\n",
            "steps32\n",
            "d loss: -1.6107, g loss: 2.4281\n",
            "epoch time: 29.5584 [sec]\n",
            "\n",
            "epochs 268\n",
            "steps32\n",
            "d loss: -1.5620, g loss: 2.4415\n",
            "epoch time: 29.5731 [sec]\n",
            "\n",
            "epochs 269\n",
            "steps32\n",
            "d loss: -1.5838, g loss: 2.4566\n",
            "epoch time: 29.5370 [sec]\n",
            "\n",
            "epochs 270\n",
            "steps32\n",
            "d loss: -1.6114, g loss: 2.4774\n",
            "epoch time: 29.6519 [sec]\n",
            "\n",
            "Saving checkpoint at epoch270\n",
            "\n",
            "\n",
            "\n",
            "epochs 271\n",
            "steps32\n",
            "d loss: -1.6773, g loss: 2.4895\n",
            "epoch time: 29.5356 [sec]\n",
            "\n",
            "epochs 272\n",
            "steps32\n",
            "d loss: -1.6605, g loss: 2.5083\n",
            "epoch time: 29.5753 [sec]\n",
            "\n",
            "epochs 273\n",
            "steps32\n",
            "d loss: -1.5430, g loss: 2.5302\n",
            "epoch time: 29.5464 [sec]\n",
            "\n",
            "epochs 274\n",
            "steps32\n",
            "d loss: -1.6363, g loss: 2.5455\n",
            "epoch time: 29.5316 [sec]\n",
            "\n",
            "epochs 275\n",
            "steps32\n",
            "d loss: -1.6655, g loss: 2.5590\n",
            "epoch time: 29.5215 [sec]\n",
            "\n",
            "epochs 276\n",
            "steps32\n",
            "d loss: -1.6181, g loss: 2.5745\n",
            "epoch time: 29.5510 [sec]\n",
            "\n",
            "epochs 277\n",
            "steps32\n",
            "d loss: -1.6455, g loss: 2.5886\n",
            "epoch time: 29.5503 [sec]\n",
            "\n",
            "epochs 278\n",
            "steps32\n",
            "d loss: -1.6127, g loss: 2.6104\n",
            "epoch time: 29.5336 [sec]\n",
            "\n",
            "epochs 279\n",
            "steps32\n",
            "d loss: -1.6925, g loss: 2.6273\n",
            "epoch time: 29.6404 [sec]\n",
            "\n",
            "epochs 280\n",
            "steps32\n",
            "d loss: -1.5160, g loss: 2.6389\n",
            "epoch time: 29.5439 [sec]\n",
            "\n",
            "Saving checkpoint at epoch280\n",
            "\n",
            "\n",
            "\n",
            "epochs 281\n",
            "steps32\n",
            "d loss: -1.7318, g loss: 2.6520\n",
            "epoch time: 29.6783 [sec]\n",
            "\n",
            "epochs 282\n",
            "steps32\n",
            "d loss: -1.6653, g loss: 2.6741\n",
            "epoch time: 29.5826 [sec]\n",
            "\n",
            "epochs 283\n",
            "steps32\n",
            "d loss: -1.6226, g loss: 2.6914\n",
            "epoch time: 29.5922 [sec]\n",
            "\n",
            "epochs 284\n",
            "steps32\n",
            "d loss: -1.6452, g loss: 2.7065\n",
            "epoch time: 29.5765 [sec]\n",
            "\n",
            "epochs 285\n",
            "steps32\n",
            "d loss: -1.6022, g loss: 2.7209\n",
            "epoch time: 29.5801 [sec]\n",
            "\n",
            "epochs 286\n",
            "steps32\n",
            "d loss: -1.5838, g loss: 2.7361\n",
            "epoch time: 29.5631 [sec]\n",
            "\n",
            "epochs 287\n",
            "steps32\n",
            "d loss: -1.5797, g loss: 2.7539\n",
            "epoch time: 29.7307 [sec]\n",
            "\n",
            "epochs 288\n",
            "steps32\n",
            "d loss: -1.6596, g loss: 2.7698\n",
            "epoch time: 29.8161 [sec]\n",
            "\n",
            "epochs 289\n",
            "steps32\n",
            "d loss: -1.7237, g loss: 2.7853\n",
            "epoch time: 29.6050 [sec]\n",
            "\n",
            "epochs 290\n",
            "steps32\n",
            "d loss: -1.6820, g loss: 2.8050\n",
            "epoch time: 29.5933 [sec]\n",
            "\n",
            "Saving checkpoint at epoch290\n",
            "\n",
            "\n",
            "\n",
            "epochs 291\n",
            "steps32\n",
            "d loss: -1.5419, g loss: 2.8220\n",
            "epoch time: 29.5607 [sec]\n",
            "\n",
            "epochs 292\n",
            "steps32\n",
            "d loss: -1.6603, g loss: 2.8395\n",
            "epoch time: 29.5808 [sec]\n",
            "\n",
            "epochs 293\n",
            "steps32\n",
            "d loss: -1.5673, g loss: 2.8578\n",
            "epoch time: 29.6862 [sec]\n",
            "\n",
            "epochs 294\n",
            "steps32\n",
            "d loss: -1.5339, g loss: 2.8700\n",
            "epoch time: 29.5410 [sec]\n",
            "\n",
            "epochs 295\n",
            "steps32\n",
            "d loss: -1.5463, g loss: 2.8876\n",
            "epoch time: 29.6096 [sec]\n",
            "\n",
            "epochs 296\n",
            "steps32\n",
            "d loss: -1.6002, g loss: 2.9030\n",
            "epoch time: 29.5972 [sec]\n",
            "\n",
            "epochs 297\n",
            "steps32\n",
            "d loss: -1.6898, g loss: 2.9183\n",
            "epoch time: 29.6116 [sec]\n",
            "\n",
            "epochs 298\n",
            "steps32\n",
            "d loss: -1.5664, g loss: 2.9373\n",
            "epoch time: 29.6078 [sec]\n",
            "\n",
            "epochs 299\n",
            "steps32\n",
            "d loss: -1.4822, g loss: 2.9512\n",
            "epoch time: 29.6138 [sec]\n",
            "\n",
            "epochs 300\n",
            "steps32\n",
            "d loss: -1.6429, g loss: 2.9649\n",
            "epoch time: 29.5711 [sec]\n",
            "\n",
            "Saving checkpoint at epoch300\n",
            "\n",
            "\n",
            "\n",
            "epochs 301\n",
            "steps32\n",
            "d loss: -1.5505, g loss: 2.9823\n",
            "epoch time: 29.8578 [sec]\n",
            "\n",
            "epochs 302\n",
            "steps32\n",
            "d loss: -1.5661, g loss: 2.9905\n",
            "epoch time: 29.5884 [sec]\n",
            "\n",
            "epochs 303\n",
            "steps32\n",
            "d loss: -1.5971, g loss: 3.0032\n",
            "epoch time: 29.6060 [sec]\n",
            "\n",
            "epochs 304\n",
            "steps32\n",
            "d loss: -1.6397, g loss: 3.0216\n",
            "epoch time: 29.5963 [sec]\n",
            "\n",
            "epochs 305\n",
            "steps32\n",
            "d loss: -1.5823, g loss: 3.0325\n",
            "epoch time: 29.5933 [sec]\n",
            "\n",
            "epochs 306\n",
            "steps32\n",
            "d loss: -1.5500, g loss: 3.0461\n",
            "epoch time: 29.6596 [sec]\n",
            "\n",
            "epochs 307\n",
            "steps32\n",
            "d loss: -1.5788, g loss: 3.0640\n",
            "epoch time: 29.5268 [sec]\n",
            "\n",
            "epochs 308\n",
            "steps32\n",
            "d loss: -1.5000, g loss: 3.0771\n",
            "epoch time: 29.6370 [sec]\n",
            "\n",
            "epochs 309\n",
            "steps32\n",
            "d loss: -1.5637, g loss: 3.0926\n",
            "epoch time: 30.2079 [sec]\n",
            "\n",
            "epochs 310\n",
            "steps32\n",
            "d loss: -1.5383, g loss: 3.1036\n",
            "epoch time: 29.5840 [sec]\n",
            "\n",
            "Saving checkpoint at epoch310\n",
            "\n",
            "\n",
            "\n",
            "epochs 311\n",
            "steps32\n",
            "d loss: -1.5472, g loss: 3.1139\n",
            "epoch time: 29.8942 [sec]\n",
            "\n",
            "epochs 312\n",
            "steps32\n",
            "d loss: -1.5100, g loss: 3.1255\n",
            "epoch time: 29.6126 [sec]\n",
            "\n",
            "epochs 313\n",
            "steps32\n",
            "d loss: -1.5176, g loss: 3.1391\n",
            "epoch time: 30.1613 [sec]\n",
            "\n",
            "epochs 314\n",
            "steps32\n",
            "d loss: -1.5642, g loss: 3.1541\n",
            "epoch time: 30.2237 [sec]\n",
            "\n",
            "epochs 315\n",
            "steps32\n",
            "d loss: -1.5446, g loss: 3.1761\n",
            "epoch time: 29.5899 [sec]\n",
            "\n",
            "epochs 316\n",
            "steps32\n",
            "d loss: -1.6112, g loss: 3.1863\n",
            "epoch time: 29.9980 [sec]\n",
            "\n",
            "epochs 317\n",
            "steps32\n",
            "d loss: -1.4232, g loss: 3.1959\n",
            "epoch time: 29.8493 [sec]\n",
            "\n",
            "epochs 318\n",
            "steps32\n",
            "d loss: -1.3859, g loss: 3.2087\n",
            "epoch time: 29.6301 [sec]\n",
            "\n",
            "epochs 319\n",
            "steps32\n",
            "d loss: -1.5236, g loss: 3.2260\n",
            "epoch time: 29.8748 [sec]\n",
            "\n",
            "epochs 320\n",
            "steps32\n",
            "d loss: -1.5791, g loss: 3.2362\n",
            "epoch time: 29.6151 [sec]\n",
            "\n",
            "Saving checkpoint at epoch320\n",
            "\n",
            "\n",
            "\n",
            "epochs 321\n",
            "steps32\n",
            "d loss: -1.5528, g loss: 3.2518\n",
            "epoch time: 29.5651 [sec]\n",
            "\n",
            "epochs 322\n",
            "steps32\n",
            "d loss: -1.5666, g loss: 3.2642\n",
            "epoch time: 29.8891 [sec]\n",
            "\n",
            "epochs 323\n",
            "steps32\n",
            "d loss: -1.4987, g loss: 3.2790\n",
            "epoch time: 29.5679 [sec]\n",
            "\n",
            "epochs 324\n",
            "steps32\n",
            "d loss: -1.5236, g loss: 3.2863\n",
            "epoch time: 29.9329 [sec]\n",
            "\n",
            "epochs 325\n",
            "steps32\n",
            "d loss: -1.6767, g loss: 3.3050\n",
            "epoch time: 29.9549 [sec]\n",
            "\n",
            "epochs 326\n",
            "steps32\n",
            "d loss: -1.4656, g loss: 3.3132\n",
            "epoch time: 29.5620 [sec]\n",
            "\n",
            "epochs 327\n",
            "steps32\n",
            "d loss: -1.4693, g loss: 3.3259\n",
            "epoch time: 29.8797 [sec]\n",
            "\n",
            "epochs 328\n",
            "steps32\n",
            "d loss: -1.5165, g loss: 3.3366\n",
            "epoch time: 29.5254 [sec]\n",
            "\n",
            "epochs 329\n",
            "steps32\n",
            "d loss: -1.3822, g loss: 3.3452\n",
            "epoch time: 36.1606 [sec]\n",
            "\n",
            "epochs 330\n",
            "steps32\n",
            "d loss: -1.5234, g loss: 3.3612\n",
            "epoch time: 29.5338 [sec]\n",
            "\n",
            "Saving checkpoint at epoch330\n",
            "\n",
            "\n",
            "\n",
            "epochs 331\n",
            "steps32\n",
            "d loss: -1.5183, g loss: 3.3712\n",
            "epoch time: 29.5615 [sec]\n",
            "\n",
            "epochs 332\n",
            "steps32\n",
            "d loss: -1.4493, g loss: 3.3845\n",
            "epoch time: 29.7196 [sec]\n",
            "\n",
            "epochs 333\n",
            "steps32\n",
            "d loss: -1.4642, g loss: 3.3979\n",
            "epoch time: 29.9720 [sec]\n",
            "\n",
            "epochs 334\n",
            "steps32\n",
            "d loss: -1.4029, g loss: 3.4064\n",
            "epoch time: 29.5786 [sec]\n",
            "\n",
            "epochs 335\n",
            "steps32\n",
            "d loss: -1.5940, g loss: 3.4169\n",
            "epoch time: 29.5400 [sec]\n",
            "\n",
            "epochs 336\n",
            "steps32\n",
            "d loss: -1.5656, g loss: 3.4269\n",
            "epoch time: 29.5434 [sec]\n",
            "\n",
            "epochs 337\n",
            "steps32\n",
            "d loss: -1.4212, g loss: 3.4388\n",
            "epoch time: 29.5632 [sec]\n",
            "\n",
            "epochs 338\n",
            "steps32\n",
            "d loss: -1.5660, g loss: 3.4548\n",
            "epoch time: 29.5479 [sec]\n",
            "\n",
            "epochs 339\n",
            "steps32\n",
            "d loss: -1.5329, g loss: 3.4650\n",
            "epoch time: 29.5529 [sec]\n",
            "\n",
            "epochs 340\n",
            "steps32\n",
            "d loss: -1.4432, g loss: 3.4797\n",
            "epoch time: 29.5415 [sec]\n",
            "\n",
            "Saving checkpoint at epoch340\n",
            "\n",
            "\n",
            "\n",
            "epochs 341\n",
            "steps32\n",
            "d loss: -1.4306, g loss: 3.4929\n",
            "epoch time: 29.6250 [sec]\n",
            "\n",
            "epochs 342\n",
            "steps32\n",
            "d loss: -1.5070, g loss: 3.5002\n",
            "epoch time: 29.5458 [sec]\n",
            "\n",
            "epochs 343\n",
            "steps32\n",
            "d loss: -1.5105, g loss: 3.5121\n",
            "epoch time: 29.5616 [sec]\n",
            "\n",
            "epochs 344\n",
            "steps32\n",
            "d loss: -1.4504, g loss: 3.5252\n",
            "epoch time: 29.5298 [sec]\n",
            "\n",
            "epochs 345\n",
            "steps32\n",
            "d loss: -1.4894, g loss: 3.5367\n",
            "epoch time: 29.5531 [sec]\n",
            "\n",
            "epochs 346\n",
            "steps32\n",
            "d loss: -1.3597, g loss: 3.5445\n",
            "epoch time: 29.5501 [sec]\n",
            "\n",
            "epochs 347\n",
            "steps32\n",
            "d loss: -1.4499, g loss: 3.5491\n",
            "epoch time: 29.5572 [sec]\n",
            "\n",
            "epochs 348\n",
            "steps32\n",
            "d loss: -1.4954, g loss: 3.5627\n",
            "epoch time: 29.5310 [sec]\n",
            "\n",
            "epochs 349\n",
            "steps32\n",
            "d loss: -1.3202, g loss: 3.5766\n",
            "epoch time: 29.5313 [sec]\n",
            "\n",
            "epochs 350\n",
            "steps32\n",
            "d loss: -1.4521, g loss: 3.5853\n",
            "epoch time: 29.5448 [sec]\n",
            "\n",
            "Saving checkpoint at epoch350\n",
            "\n",
            "\n",
            "\n",
            "epochs 351\n",
            "steps32\n",
            "d loss: -1.3620, g loss: 3.5997\n",
            "epoch time: 29.5849 [sec]\n",
            "\n",
            "epochs 352\n",
            "steps32\n",
            "d loss: -1.4922, g loss: 3.6087\n",
            "epoch time: 29.5285 [sec]\n",
            "\n",
            "epochs 353\n",
            "steps32\n",
            "d loss: -1.3955, g loss: 3.6229\n",
            "epoch time: 29.5569 [sec]\n",
            "\n",
            "epochs 354\n",
            "steps32\n",
            "d loss: -1.5407, g loss: 3.6361\n",
            "epoch time: 29.5762 [sec]\n",
            "\n",
            "epochs 355\n",
            "steps32\n",
            "d loss: -1.5480, g loss: 3.6442\n",
            "epoch time: 29.5559 [sec]\n",
            "\n",
            "epochs 356\n",
            "steps32\n",
            "d loss: -1.4997, g loss: 3.6564\n",
            "epoch time: 29.5500 [sec]\n",
            "\n",
            "epochs 357\n",
            "steps32\n",
            "d loss: -1.3788, g loss: 3.6669\n",
            "epoch time: 29.5708 [sec]\n",
            "\n",
            "epochs 358\n",
            "steps32\n",
            "d loss: -1.4896, g loss: 3.6772\n",
            "epoch time: 29.5620 [sec]\n",
            "\n",
            "epochs 359\n",
            "steps32\n",
            "d loss: -1.4755, g loss: 3.6872\n",
            "epoch time: 29.5496 [sec]\n",
            "\n",
            "epochs 360\n",
            "steps32\n",
            "d loss: -1.4967, g loss: 3.6938\n",
            "epoch time: 29.5651 [sec]\n",
            "\n",
            "Saving checkpoint at epoch360\n",
            "\n",
            "\n",
            "\n",
            "epochs 361\n",
            "steps32\n",
            "d loss: -1.6126, g loss: 3.7117\n",
            "epoch time: 29.6098 [sec]\n",
            "\n",
            "epochs 362\n",
            "steps32\n",
            "d loss: -1.4878, g loss: 3.7277\n",
            "epoch time: 29.5437 [sec]\n",
            "\n",
            "epochs 363\n",
            "steps32\n",
            "d loss: -1.4795, g loss: 3.7387\n",
            "epoch time: 29.5468 [sec]\n",
            "\n",
            "epochs 364\n",
            "steps32\n",
            "d loss: -1.4665, g loss: 3.7488\n",
            "epoch time: 29.5698 [sec]\n",
            "\n",
            "epochs 365\n",
            "steps32\n",
            "d loss: -1.4202, g loss: 3.7614\n",
            "epoch time: 29.5235 [sec]\n",
            "\n",
            "epochs 366\n",
            "steps32\n",
            "d loss: -1.4500, g loss: 3.7743\n",
            "epoch time: 29.5522 [sec]\n",
            "\n",
            "epochs 367\n",
            "steps32\n",
            "d loss: -1.5333, g loss: 3.7821\n",
            "epoch time: 29.5552 [sec]\n",
            "\n",
            "epochs 368\n",
            "steps32\n",
            "d loss: -1.3932, g loss: 3.7935\n",
            "epoch time: 29.5593 [sec]\n",
            "\n",
            "epochs 369\n",
            "steps32\n",
            "d loss: -1.3689, g loss: 3.8038\n",
            "epoch time: 29.5184 [sec]\n",
            "\n",
            "epochs 370\n",
            "steps32\n",
            "d loss: -1.4687, g loss: 3.8173\n",
            "epoch time: 29.5289 [sec]\n",
            "\n",
            "Saving checkpoint at epoch370\n",
            "\n",
            "\n",
            "\n",
            "epochs 371\n",
            "steps32\n",
            "d loss: -1.3902, g loss: 3.8273\n",
            "epoch time: 29.5861 [sec]\n",
            "\n",
            "epochs 372\n",
            "steps32\n",
            "d loss: -1.3882, g loss: 3.8379\n",
            "epoch time: 29.5123 [sec]\n",
            "\n",
            "epochs 373\n",
            "steps32\n",
            "d loss: -1.4875, g loss: 3.8483\n",
            "epoch time: 29.5705 [sec]\n",
            "\n",
            "epochs 374\n",
            "steps32\n",
            "d loss: -1.4105, g loss: 3.8541\n",
            "epoch time: 29.5494 [sec]\n",
            "\n",
            "epochs 375\n",
            "steps32\n",
            "d loss: -1.4582, g loss: 3.8662\n",
            "epoch time: 29.5134 [sec]\n",
            "\n",
            "epochs 376\n",
            "steps32\n",
            "d loss: -1.4352, g loss: 3.8777\n",
            "epoch time: 29.5382 [sec]\n",
            "\n",
            "epochs 377\n",
            "steps32\n",
            "d loss: -1.4140, g loss: 3.8908\n",
            "epoch time: 29.5550 [sec]\n",
            "\n",
            "epochs 378\n",
            "steps32\n",
            "d loss: -1.4940, g loss: 3.9002\n",
            "epoch time: 29.5566 [sec]\n",
            "\n",
            "epochs 379\n",
            "steps32\n",
            "d loss: -1.4086, g loss: 3.9126\n",
            "epoch time: 29.5126 [sec]\n",
            "\n",
            "epochs 380\n",
            "steps32\n",
            "d loss: -1.6134, g loss: 3.9229\n",
            "epoch time: 29.5462 [sec]\n",
            "\n",
            "Saving checkpoint at epoch380\n",
            "\n",
            "\n",
            "\n",
            "epochs 381\n",
            "steps32\n",
            "d loss: -1.4579, g loss: 3.9363\n",
            "epoch time: 29.6002 [sec]\n",
            "\n",
            "epochs 382\n",
            "steps32\n",
            "d loss: -1.5533, g loss: 3.9485\n",
            "epoch time: 29.5270 [sec]\n",
            "\n",
            "epochs 383\n",
            "steps32\n",
            "d loss: -1.4535, g loss: 3.9582\n",
            "epoch time: 29.5582 [sec]\n",
            "\n",
            "epochs 384\n",
            "steps32\n",
            "d loss: -1.5821, g loss: 3.9745\n",
            "epoch time: 29.5689 [sec]\n",
            "\n",
            "epochs 385\n",
            "steps32\n",
            "d loss: -1.5067, g loss: 3.9835\n",
            "epoch time: 29.5459 [sec]\n",
            "\n",
            "epochs 386\n",
            "steps32\n",
            "d loss: -1.4004, g loss: 3.9930\n",
            "epoch time: 29.5394 [sec]\n",
            "\n",
            "epochs 387\n",
            "steps32\n",
            "d loss: -1.6257, g loss: 4.0017\n",
            "epoch time: 29.5481 [sec]\n",
            "\n",
            "epochs 388\n",
            "steps32\n",
            "d loss: -1.3494, g loss: 4.0181\n",
            "epoch time: 29.5258 [sec]\n",
            "\n",
            "epochs 389\n",
            "steps32\n",
            "d loss: -1.6405, g loss: 4.0249\n",
            "epoch time: 29.5157 [sec]\n",
            "\n",
            "epochs 390\n",
            "steps32\n",
            "d loss: -1.5248, g loss: 4.0317\n",
            "epoch time: 29.5237 [sec]\n",
            "\n",
            "Saving checkpoint at epoch390\n",
            "\n",
            "\n",
            "\n",
            "epochs 391\n",
            "steps32\n",
            "d loss: -1.3181, g loss: 4.0432\n",
            "epoch time: 29.5361 [sec]\n",
            "\n",
            "epochs 392\n",
            "steps32\n",
            "d loss: -1.5749, g loss: 4.0555\n",
            "epoch time: 29.5366 [sec]\n",
            "\n",
            "epochs 393\n",
            "steps32\n",
            "d loss: -1.5186, g loss: 4.0693\n",
            "epoch time: 29.5396 [sec]\n",
            "\n",
            "epochs 394\n",
            "steps32\n",
            "d loss: -1.5196, g loss: 4.0823\n",
            "epoch time: 29.5687 [sec]\n",
            "\n",
            "epochs 395\n",
            "steps32\n",
            "d loss: -1.4882, g loss: 4.0933\n",
            "epoch time: 29.5324 [sec]\n",
            "\n",
            "epochs 396\n",
            "steps32\n",
            "d loss: -1.7407, g loss: 4.1060\n",
            "epoch time: 29.5422 [sec]\n",
            "\n",
            "epochs 397\n",
            "steps32\n",
            "d loss: -1.6516, g loss: 4.1245\n",
            "epoch time: 29.5403 [sec]\n",
            "\n",
            "epochs 398\n",
            "steps32\n",
            "d loss: -1.6491, g loss: 4.1322\n",
            "epoch time: 29.5831 [sec]\n",
            "\n",
            "epochs 399\n",
            "steps32\n",
            "d loss: -1.6771, g loss: 4.1428\n",
            "epoch time: 29.5129 [sec]\n",
            "\n",
            "epochs 400\n",
            "steps32\n",
            "d loss: -1.5841, g loss: 4.1516\n",
            "epoch time: 29.5334 [sec]\n",
            "\n",
            "Saving checkpoint at epoch400\n",
            "\n",
            "\n",
            "\n",
            "epochs 401\n",
            "steps32\n",
            "d loss: -1.6996, g loss: 4.1606\n",
            "epoch time: 29.6021 [sec]\n",
            "\n",
            "epochs 402\n",
            "steps32\n",
            "d loss: -1.7199, g loss: 4.1776\n",
            "epoch time: 29.5441 [sec]\n",
            "\n",
            "epochs 403\n",
            "steps32\n",
            "d loss: -1.6530, g loss: 4.1927\n",
            "epoch time: 29.5888 [sec]\n",
            "\n",
            "epochs 404\n",
            "steps32\n",
            "d loss: -1.5993, g loss: 4.2045\n",
            "epoch time: 29.5387 [sec]\n",
            "\n",
            "epochs 405\n",
            "steps32\n",
            "d loss: -1.7239, g loss: 4.2181\n",
            "epoch time: 29.5591 [sec]\n",
            "\n",
            "epochs 406\n",
            "steps32\n",
            "d loss: -1.7752, g loss: 4.2363\n",
            "epoch time: 29.5618 [sec]\n",
            "\n",
            "epochs 407\n",
            "steps32\n",
            "d loss: -1.6215, g loss: 4.2492\n",
            "epoch time: 29.5459 [sec]\n",
            "\n",
            "epochs 408\n",
            "steps32\n",
            "d loss: -1.8200, g loss: 4.2589\n",
            "epoch time: 29.5329 [sec]\n",
            "\n",
            "epochs 409\n",
            "steps32\n",
            "d loss: -1.7474, g loss: 4.2773\n",
            "epoch time: 29.5488 [sec]\n",
            "\n",
            "epochs 410\n",
            "steps32\n",
            "d loss: -1.6563, g loss: 4.2850\n",
            "epoch time: 29.5122 [sec]\n",
            "\n",
            "Saving checkpoint at epoch410\n",
            "\n",
            "\n",
            "\n",
            "epochs 411\n",
            "steps32\n",
            "d loss: -1.7208, g loss: 4.3013\n",
            "epoch time: 29.5504 [sec]\n",
            "\n",
            "epochs 412\n",
            "steps32\n",
            "d loss: -1.5965, g loss: 4.3095\n",
            "epoch time: 29.5722 [sec]\n",
            "\n",
            "epochs 413\n",
            "steps32\n",
            "d loss: -1.7729, g loss: 4.3221\n",
            "epoch time: 29.5405 [sec]\n",
            "\n",
            "epochs 414\n",
            "steps32\n",
            "d loss: -1.5788, g loss: 4.3373\n",
            "epoch time: 29.5649 [sec]\n",
            "\n",
            "epochs 415\n",
            "steps32\n",
            "d loss: -1.7081, g loss: 4.3588\n",
            "epoch time: 29.5483 [sec]\n",
            "\n",
            "epochs 416\n",
            "steps32\n",
            "d loss: -1.8228, g loss: 4.3774\n",
            "epoch time: 29.5098 [sec]\n",
            "\n",
            "epochs 417\n",
            "steps32\n",
            "d loss: -1.7525, g loss: 4.3936\n",
            "epoch time: 29.5342 [sec]\n",
            "\n",
            "epochs 418\n",
            "steps32\n",
            "d loss: -1.7194, g loss: 4.4140\n",
            "epoch time: 29.5557 [sec]\n",
            "\n",
            "epochs 419\n",
            "steps32\n",
            "d loss: -1.8256, g loss: 4.4264\n",
            "epoch time: 29.5783 [sec]\n",
            "\n",
            "epochs 420\n",
            "steps32\n",
            "d loss: -1.8267, g loss: 4.4472\n",
            "epoch time: 29.5465 [sec]\n",
            "\n",
            "Saving checkpoint at epoch420\n",
            "\n",
            "\n",
            "\n",
            "epochs 421\n",
            "steps32\n",
            "d loss: -2.0452, g loss: 4.4613\n",
            "epoch time: 29.6143 [sec]\n",
            "\n",
            "epochs 422\n",
            "steps32\n",
            "d loss: -1.9071, g loss: 4.4807\n",
            "epoch time: 29.5443 [sec]\n",
            "\n",
            "epochs 423\n",
            "steps32\n",
            "d loss: -1.8844, g loss: 4.4938\n",
            "epoch time: 29.5342 [sec]\n",
            "\n",
            "epochs 424\n",
            "steps32\n",
            "d loss: -2.0006, g loss: 4.5136\n",
            "epoch time: 29.5495 [sec]\n",
            "\n",
            "epochs 425\n",
            "steps32\n",
            "d loss: -1.9430, g loss: 4.5408\n",
            "epoch time: 29.5798 [sec]\n",
            "\n",
            "epochs 426\n",
            "steps32\n",
            "d loss: -2.0282, g loss: 4.5578\n",
            "epoch time: 29.5552 [sec]\n",
            "\n",
            "epochs 427\n",
            "steps32\n",
            "d loss: -1.9487, g loss: 4.5848\n",
            "epoch time: 29.5308 [sec]\n",
            "\n",
            "epochs 428\n",
            "steps32\n",
            "d loss: -2.0435, g loss: 4.6003\n",
            "epoch time: 29.5452 [sec]\n",
            "\n",
            "epochs 429\n",
            "steps32\n",
            "d loss: -1.9889, g loss: 4.6177\n",
            "epoch time: 29.5586 [sec]\n",
            "\n",
            "epochs 430\n",
            "steps32\n",
            "d loss: -2.1329, g loss: 4.6318\n",
            "epoch time: 29.5231 [sec]\n",
            "\n",
            "Saving checkpoint at epoch430\n",
            "\n",
            "\n",
            "\n",
            "epochs 431\n",
            "steps32\n",
            "d loss: -2.1176, g loss: 4.6572\n",
            "epoch time: 29.5797 [sec]\n",
            "\n",
            "epochs 432\n",
            "steps32\n",
            "d loss: -2.0402, g loss: 4.6770\n",
            "epoch time: 29.5524 [sec]\n",
            "\n",
            "epochs 433\n",
            "steps32\n",
            "d loss: -2.0433, g loss: 4.7020\n",
            "epoch time: 29.5340 [sec]\n",
            "\n",
            "epochs 434\n",
            "steps32\n",
            "d loss: -2.0102, g loss: 4.7271\n",
            "epoch time: 29.5187 [sec]\n",
            "\n",
            "epochs 435\n",
            "steps32\n",
            "d loss: -2.1179, g loss: 4.7455\n",
            "epoch time: 29.5917 [sec]\n",
            "\n",
            "epochs 436\n",
            "steps32\n",
            "d loss: -2.1468, g loss: 4.7691\n",
            "epoch time: 29.5415 [sec]\n",
            "\n",
            "epochs 437\n",
            "steps32\n",
            "d loss: -2.0320, g loss: 4.7895\n",
            "epoch time: 29.5490 [sec]\n",
            "\n",
            "epochs 438\n",
            "steps32\n",
            "d loss: -2.1643, g loss: 4.8141\n",
            "epoch time: 29.5298 [sec]\n",
            "\n",
            "epochs 439\n",
            "steps32\n",
            "d loss: -2.1337, g loss: 4.8386\n",
            "epoch time: 29.5508 [sec]\n",
            "\n",
            "epochs 440\n",
            "steps32\n",
            "d loss: -2.3669, g loss: 4.8728\n",
            "epoch time: 29.5501 [sec]\n",
            "\n",
            "Saving checkpoint at epoch440\n",
            "\n",
            "\n",
            "\n",
            "epochs 441\n",
            "steps32\n",
            "d loss: -2.2406, g loss: 4.8969\n",
            "epoch time: 29.5578 [sec]\n",
            "\n",
            "epochs 442\n",
            "steps32\n",
            "d loss: -2.1289, g loss: 4.9226\n",
            "epoch time: 29.5557 [sec]\n",
            "\n",
            "epochs 443\n",
            "steps32\n",
            "d loss: -2.2575, g loss: 4.9524\n",
            "epoch time: 29.5632 [sec]\n",
            "\n",
            "epochs 444\n",
            "steps32\n",
            "d loss: -2.2118, g loss: 4.9736\n",
            "epoch time: 29.5370 [sec]\n",
            "\n",
            "epochs 445\n",
            "steps32\n",
            "d loss: -2.3229, g loss: 4.9996\n",
            "epoch time: 29.5328 [sec]\n",
            "\n",
            "epochs 446\n",
            "steps32\n",
            "d loss: -2.3641, g loss: 5.0274\n",
            "epoch time: 29.5498 [sec]\n",
            "\n",
            "epochs 447\n",
            "steps32\n",
            "d loss: -2.3778, g loss: 5.0586\n",
            "epoch time: 29.5380 [sec]\n",
            "\n",
            "epochs 448\n",
            "steps32\n",
            "d loss: -2.2238, g loss: 5.0790\n",
            "epoch time: 29.5627 [sec]\n",
            "\n",
            "epochs 449\n",
            "steps32\n",
            "d loss: -2.3820, g loss: 5.0980\n",
            "epoch time: 29.5763 [sec]\n",
            "\n",
            "epochs 450\n",
            "steps32\n",
            "d loss: -2.3501, g loss: 5.1379\n",
            "epoch time: 29.5302 [sec]\n",
            "\n",
            "Saving checkpoint at epoch450\n",
            "\n",
            "\n",
            "\n",
            "epochs 451\n",
            "steps32\n",
            "d loss: -2.5355, g loss: 5.1697\n",
            "epoch time: 29.5708 [sec]\n",
            "\n",
            "epochs 452\n",
            "steps32\n",
            "d loss: -2.4435, g loss: 5.2008\n",
            "epoch time: 29.5372 [sec]\n",
            "\n",
            "epochs 453\n",
            "steps32\n",
            "d loss: -2.3704, g loss: 5.2265\n",
            "epoch time: 29.5318 [sec]\n",
            "\n",
            "epochs 454\n",
            "steps32\n",
            "d loss: -2.5512, g loss: 5.2589\n",
            "epoch time: 29.5353 [sec]\n",
            "\n",
            "epochs 455\n",
            "steps32\n",
            "d loss: -2.5202, g loss: 5.2886\n",
            "epoch time: 29.5514 [sec]\n",
            "\n",
            "epochs 456\n",
            "steps32\n",
            "d loss: -2.4519, g loss: 5.3175\n",
            "epoch time: 29.5400 [sec]\n",
            "\n",
            "epochs 457\n",
            "steps32\n",
            "d loss: -2.4202, g loss: 5.3471\n",
            "epoch time: 29.5267 [sec]\n",
            "\n",
            "epochs 458\n",
            "steps32\n",
            "d loss: -2.6410, g loss: 5.3729\n",
            "epoch time: 29.5612 [sec]\n",
            "\n",
            "epochs 459\n",
            "steps32\n",
            "d loss: -2.3799, g loss: 5.3923\n",
            "epoch time: 29.5291 [sec]\n",
            "\n",
            "epochs 460\n",
            "steps32\n",
            "d loss: -2.6092, g loss: 5.4277\n",
            "epoch time: 29.5259 [sec]\n",
            "\n",
            "Saving checkpoint at epoch460\n",
            "\n",
            "\n",
            "\n",
            "epochs 461\n",
            "steps32\n",
            "d loss: -2.6892, g loss: 5.4648\n",
            "epoch time: 29.5740 [sec]\n",
            "\n",
            "epochs 462\n",
            "steps32\n",
            "d loss: -2.6414, g loss: 5.5000\n",
            "epoch time: 29.5420 [sec]\n",
            "\n",
            "epochs 463\n",
            "steps32\n",
            "d loss: -2.5915, g loss: 5.5313\n",
            "epoch time: 29.5534 [sec]\n",
            "\n",
            "epochs 464\n",
            "steps32\n",
            "d loss: -2.7645, g loss: 5.5598\n",
            "epoch time: 29.5116 [sec]\n",
            "\n",
            "epochs 465\n",
            "steps32\n",
            "d loss: -2.6701, g loss: 5.5983\n",
            "epoch time: 29.5271 [sec]\n",
            "\n",
            "epochs 466\n",
            "steps32\n",
            "d loss: -2.7048, g loss: 5.6293\n",
            "epoch time: 29.5352 [sec]\n",
            "\n",
            "epochs 467\n",
            "steps32\n",
            "d loss: -2.7419, g loss: 5.6528\n",
            "epoch time: 29.5279 [sec]\n",
            "\n",
            "epochs 468\n",
            "steps32\n",
            "d loss: -2.9656, g loss: 5.6898\n",
            "epoch time: 29.5567 [sec]\n",
            "\n",
            "epochs 469\n",
            "steps32\n",
            "d loss: -2.9208, g loss: 5.7179\n",
            "epoch time: 29.5227 [sec]\n",
            "\n",
            "epochs 470\n",
            "steps32\n",
            "d loss: -2.8216, g loss: 5.7478\n",
            "epoch time: 29.5512 [sec]\n",
            "\n",
            "Saving checkpoint at epoch470\n",
            "\n",
            "\n",
            "\n",
            "epochs 471\n",
            "steps32\n",
            "d loss: -2.9566, g loss: 5.7774\n",
            "epoch time: 29.5955 [sec]\n",
            "\n",
            "epochs 472\n",
            "steps32\n",
            "d loss: -2.9039, g loss: 5.8071\n",
            "epoch time: 29.5191 [sec]\n",
            "\n",
            "epochs 473\n",
            "steps8"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8439bdfd2974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m            \u001b[0mgp_lamda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m            )\n\u001b[0;32m--> 239\u001b[0;31m   \u001b[0ma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-8439bdfd2974>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_critics\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_loss_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-8439bdfd2974>\u001b[0m in \u001b[0;36mg_train\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mgradients_of_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    264\u001b[0m     factor = _safe_shape_div(\n\u001b[1;32m    265\u001b[0m         math_ops.reduce_prod(input_shape), math_ops.reduce_prod(output_shape))\n\u001b[0;32m--> 266\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruediv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtruediv\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m   \"\"\"\n\u001b[0;32m-> 1297\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_truediv_python3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1234\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mreal_div\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   7438\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   7439\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RealDiv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7440\u001b[0;31m         tld.op_callbacks, x, y)\n\u001b[0m\u001b[1;32m   7441\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7442\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}